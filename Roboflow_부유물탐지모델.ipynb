{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOangFd0EqK5nhsS/rFktdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yje0515/Flotting-matters-detect/blob/main/Roboflow_%EB%B6%80%EC%9C%A0%EB%AC%BC%ED%83%90%EC%A7%80%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CfI_CcuiKZzS",
        "outputId": "4d907883-6689-462d-a97d-3f78114a8cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
            "Collecting Ultralytics\n",
            "  Downloading ultralytics-8.3.232-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from Ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from Ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->Ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->Ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->Ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->Ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->Ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->Ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->Ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->Ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->Ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.232-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, Ultralytics\n",
            "Successfully installed Ultralytics-8.3.232 ultralytics-thop-2.0.18\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ë¡œë³´í”Œë¡œìš° SDK ì„¤ì¹˜\n",
        "!pip install roboflow\n",
        "\n",
        "# Ultralytics YOLOv8 ì„¤ì¹˜\n",
        "!pip install Ultralytics\n",
        "\n",
        "# êµ¬ê¸€ë“œë¼ì´ë¸Œì— ìµœìƒì˜ ëª¨ë¸ ì €ì¥\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¡œë³´í”Œë¡œìš°ì—ì„œ YOLOv8 í˜•ì‹ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Xz2arQdZi1wxqtq3A4FW\") # apií‚¤\n",
        "project = rf.workspace(\"mbc320yje\").project(\"floating-matters-mmivq\") # ì›Œí¬ìŠ¤í˜ì´ìŠ¤, í”„ë¡œì íŠ¸ëª…\n",
        "version = project.version(3) # ë²„ì „ 3 ë°ì´í„°ì…‹ ì‚¬ìš©\n",
        "dataset = version.download(\"yolov8\") # YOLOv8 í˜•ì‹ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ(ì´ë¯¸ì§€,ë¼ë²¨,data.yaml í¬í•¨)\n",
        "\n",
        "# ë‹¤ìš´ë¡œë“œëœ í´ë” ê²½ë¡œ\n",
        "print(\"ë°ì´í„°ì…‹ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ:\", dataset.location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5XttrXqwK0U5",
        "outputId": "7e27ddae-677c-4c08-93ae-6e523b50690f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in floating-matters-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85020/85020 [00:01<00:00, 71116.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to floating-matters-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7136/7136 [00:00<00:00, 8854.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "ë°ì´í„°ì…‹ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ: /content/floating-matters-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 ë²„ì „ ë¶ˆëŸ¬ì˜¤ê¸°, í•™ìŠµ ì„¤ì •\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# data.yaml ê²½ë¡œ ì„¤ì •\n",
        "data_yaml_path = os.path.join(dataset.location, \"data.yaml\")\n",
        "print(\"data.yaml ê²½ë¡œ:\", data_yaml_path)\n",
        "\n",
        "# ìšœë¡œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model = YOLO(\"yolov8n.pt\") # yolov8n.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0dgkSriLZQ5",
        "outputId": "943c0cc3-a4c5-4f19-ab45-78637dac37f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml ê²½ë¡œ: /content/floating-matters-3/data.yaml\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 79.5MB/s 0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ëª…\n",
        "# - data: data.yaml ê²½ë¡œ (train/val/test ì •ë³´, í´ë˜ìŠ¤ëª… í¬í•¨)\n",
        "# - epochs: ì „ì²´ ë°ì´í„°ì…‹ ëª‡ ë°”í€´ ëŒë¦´ì§€ (ì§€ì€ë‹˜ì—ê² 80 ì¶”ì²œ)\n",
        "# - imgsz: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (ë³´í†µ 640 ì‚¬ìš©)\n",
        "# - patience: Early Stopping (í–¥ìƒ ì—†ì„ ë•Œ ê¸°ë‹¤ë¦¬ëŠ” epoch ìˆ˜)\n",
        "# - batch: ë°°ì¹˜ í¬ê¸°, -1ì€ ìë™ ê²°ì • (GPU ë³´ê³  ì•Œì•„ì„œ)\n",
        "# - device: 0 -> GPU, 'cpu' -> CPU\n",
        "# - name: ê²°ê³¼ê°€ ì €ì¥ë  í´ë” ì´ë¦„ (runs/detect/{name})"
      ],
      "metadata": {
        "id": "-FcQNrScMo8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=80,       # gptê°€ ì¶”ì²œí•´ì¤€ ê°’\n",
        "    imgsz=640,\n",
        "    patience=2,      # 2ë²ˆ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ë©ˆì¶¤\n",
        "    batch=-1,        # ê°€ëŠ¥í•œ ìµœëŒ€ ë°°ì¹˜ë¡œ ìë™ ì„¤ì •\n",
        "    device=0,        # GPU ì‚¬ìš© (Colab GPU ëŸ°íƒ€ì„ì—ì„œ)\n",
        "    name=\"floating_matters_yolov8n_v3\"  # ê²°ê³¼ í´ë” ì´ë¦„\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwV7k5c4MrqX",
        "outputId": "61507609-ec2f-4c96-8ed5-1aad1c5385dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.232 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/floating-matters-3/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=80, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=floating_matters_yolov8n_v3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=2, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/floating_matters_yolov8n_v3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 16.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 69.1MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 940.5Â±296.4 MB/s, size: 22.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/floating-matters-3/train/labels... 3080 images, 51 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3080/3080 2.0Kit/s 1.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/floating-matters-3/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 6976, len(boxes) = 12920. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.10G reserved, 0.06G allocated, 14.58G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     3011238       8.195         0.382         70.67         599.4        (1, 3, 640, 640)                    list\n",
            "     3011238       16.39         0.524         19.22         160.7        (2, 3, 640, 640)                    list\n",
            "     3011238       32.78         0.828         20.56           156        (4, 3, 640, 640)                    list\n",
            "     3011238       65.56         1.416         31.68         153.2        (8, 3, 640, 640)                    list\n",
            "     3011238       131.1         2.512         61.21         173.1       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 61 for CUDA:0 9.09G/14.74G (62%) âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1098.8Â±412.0 MB/s, size: 22.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/floating-matters-3/train/labels.cache... 3080 images, 51 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3080/3080 6.5Mit/s 0.0s\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 6976, len(boxes) = 12920. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 538.2Â±187.8 MB/s, size: 22.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/floating-matters-3/valid/labels... 321 images, 10 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 321/321 1.4Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/floating-matters-3/valid/images/test_yolo_mp4-0397_jpg.rf.b5f2962fe2a3e9d03df51de17bd20317.jpg: 3 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/floating-matters-3/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 767, len(boxes) = 1265. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/floating_matters_yolov8n_v3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0004765625), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/floating_matters_yolov8n_v3\u001b[0m\n",
            "Starting training for 80 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/80      7.52G      1.391      1.791      1.241        190        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.1s/it 56.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.8s/it 8.3s\n",
            "                   all        321       1265      0.954      0.427      0.852      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/80       6.9G      1.275      1.079      1.208        166        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.0s/it 51.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.6s/it 4.8s\n",
            "                   all        321       1265      0.844      0.837       0.86      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/80      6.92G      1.288     0.9971      1.227        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.1it/s 48.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.2s/it 3.7s\n",
            "                   all        321       1265      0.619      0.717        0.8      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/80      6.94G      1.271     0.9089      1.226        205        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.0it/s 49.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.2s/it 3.5s\n",
            "                   all        321       1265      0.896      0.852       0.89      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/80      6.96G      1.244     0.8487      1.217        178        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.1s/it 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.3s/it 3.8s\n",
            "                   all        321       1265       0.88      0.919       0.92      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/80      6.97G      1.212     0.7973        1.2        192        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.1s/it 56.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.6s/it 4.8s\n",
            "                   all        321       1265      0.928      0.909      0.919      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/80      6.99G      1.174     0.7721      1.191        200        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.0it/s 50.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5s/it 4.6s\n",
            "                   all        321       1265      0.918      0.906      0.915      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/80      7.01G      1.161     0.7451      1.184        192        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 51/51 1.0it/s 49.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.0it/s 3.0s\n",
            "                   all        321       1265      0.937      0.906      0.919      0.683\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 2 epochs. Best results observed at epoch 6, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=2) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "8 epochs completed in 0.128 hours.\n",
            "Optimizer stripped from /content/runs/detect/floating_matters_yolov8n_v3/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/floating_matters_yolov8n_v3/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/floating_matters_yolov8n_v3/weights/best.pt...\n",
            "Ultralytics 8.3.232 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.6s/it 7.7s\n",
            "                   all        321       1265      0.928      0.909      0.919      0.683\n",
            "               plastic         96        446      0.945      0.913      0.907       0.72\n",
            "                  twig        230        819      0.911      0.906      0.932      0.647\n",
            "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 7.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/floating_matters_yolov8n_v3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµëœ Best ëª¨ë¸ ê²½ë¡œ\n",
        "\n",
        "# Ultralytics ê¸°ë³¸ ì €ì¥ ê²½ë¡œ:\n",
        "# runs/detect/{name}/weights/best.pt\n",
        "\n",
        "run_name = \"floating_matters_yolov8n_v3\" # ìœ„ì—ì„œ ì“´ ê²°ê³¼í´ë” ì´ë¦„ê³¼ ë™ì¼í•˜ê²Œ\n",
        "best_model_path = f\"runs/detect/{run_name}/weights/best.pt\"\n",
        "\n",
        "print(\"âœ… í•™ìŠµì´ ì™„ë£Œëœ best ëª¨ë¸ ê²½ë¡œ:\")\n",
        "print(best_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT8rDxOLNVBw",
        "outputId": "b089c874-fbd4-45d1-b821-fb97d55eb1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… í•™ìŠµì´ ì™„ë£Œëœ best ëª¨ë¸ ê²½ë¡œ:\n",
            "runs/detect/floating_matters_yolov8n_v3/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµëœ Best ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ì˜ˆì¸¡(predict) í•´ë³´ê¸°\n",
        "\n",
        "best_model = YOLO(best_model_path)\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€/ ì˜ìƒ ê²½ë¡œ ì§€ì •\n",
        "# 1) ì´ë¯¸ì§€ í•˜ë‚˜ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ:\n",
        "# test_source = os.path.join(dataset.location, \"test\", \"images\")\n",
        "#   -> test í´ë”ì— ìˆëŠ” ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ ì˜ˆì¸¡\n",
        "\n",
        "# 2) ë§Œì•½ ìì‹ ì˜ ì´ë¯¸ì§€/ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì„œ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ë‹¤ë©´:\n",
        "test_source = \"/content/test_yolo.mp4\"\n",
        "\n",
        "\n",
        "# í•™ìŠµëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡í•  ì˜ìƒì— ê°ì²´íƒì§€ ë°•ìŠ¤ ì”Œì›Œì„œ ì €ì¥\n",
        "predict_results = best_model.predict(\n",
        "    source=test_source,        # ì…ë ¥ ì˜ìƒ\n",
        "    save=True,                 # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥\n",
        "    conf=0.4,                  # confidence threshold (0.0~1.0)\n",
        "    iou=0.5,                   # IoU threshold\n",
        "    name=\"floating_matters_video_v3\",  # ì¶œë ¥ í´ë”ëª… (runs/detect ì•„ë˜ ìƒì„±ë¨)\n",
        "    device=0                   # GPU ì‚¬ìš©\n",
        ")\n",
        "\n",
        "output_path = \"runs/detect/floating_matters_video_v3\"\n",
        "\n",
        "print(\"ğŸ‰ ê°ì²´ íƒì§€ ê²°ê³¼ ì˜ìƒì´ ì €ì¥ëœ í´ë”:\")\n",
        "print(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlIjO56uOU1v",
        "outputId": "d0388d81-2ef9-4f62-d333-98eca8d49fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING âš ï¸ \n",
            "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.5ms\n",
            "video 1/1 (frame 2/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.8ms\n",
            "video 1/1 (frame 3/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.9ms\n",
            "video 1/1 (frame 4/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.0ms\n",
            "video 1/1 (frame 5/2022) /content/test_yolo.mp4: 384x640 1 twig, 5.9ms\n",
            "video 1/1 (frame 6/2022) /content/test_yolo.mp4: 384x640 1 twig, 8.3ms\n",
            "video 1/1 (frame 7/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.0ms\n",
            "video 1/1 (frame 8/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.2ms\n",
            "video 1/1 (frame 9/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.3ms\n",
            "video 1/1 (frame 10/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.3ms\n",
            "video 1/1 (frame 11/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.2ms\n",
            "video 1/1 (frame 12/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.5ms\n",
            "video 1/1 (frame 13/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.0ms\n",
            "video 1/1 (frame 14/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.6ms\n",
            "video 1/1 (frame 15/2022) /content/test_yolo.mp4: 384x640 1 twig, 5.8ms\n",
            "video 1/1 (frame 16/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.3ms\n",
            "video 1/1 (frame 17/2022) /content/test_yolo.mp4: 384x640 2 twigs, 5.8ms\n",
            "video 1/1 (frame 18/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 19/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.5ms\n",
            "video 1/1 (frame 20/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.7ms\n",
            "video 1/1 (frame 21/2022) /content/test_yolo.mp4: 384x640 2 twigs, 5.8ms\n",
            "video 1/1 (frame 22/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.7ms\n",
            "video 1/1 (frame 23/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.9ms\n",
            "video 1/1 (frame 24/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.9ms\n",
            "video 1/1 (frame 25/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.3ms\n",
            "video 1/1 (frame 26/2022) /content/test_yolo.mp4: 384x640 2 twigs, 10.1ms\n",
            "video 1/1 (frame 27/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 28/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 29/2022) /content/test_yolo.mp4: 384x640 2 twigs, 5.8ms\n",
            "video 1/1 (frame 30/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.5ms\n",
            "video 1/1 (frame 31/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.0ms\n",
            "video 1/1 (frame 32/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.5ms\n",
            "video 1/1 (frame 33/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.6ms\n",
            "video 1/1 (frame 34/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.6ms\n",
            "video 1/1 (frame 35/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.3ms\n",
            "video 1/1 (frame 36/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.4ms\n",
            "video 1/1 (frame 37/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.4ms\n",
            "video 1/1 (frame 38/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 39/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.3ms\n",
            "video 1/1 (frame 40/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.0ms\n",
            "video 1/1 (frame 41/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.8ms\n",
            "video 1/1 (frame 42/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.9ms\n",
            "video 1/1 (frame 43/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.4ms\n",
            "video 1/1 (frame 44/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.1ms\n",
            "video 1/1 (frame 45/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.5ms\n",
            "video 1/1 (frame 46/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 47/2022) /content/test_yolo.mp4: 384x640 2 twigs, 10.2ms\n",
            "video 1/1 (frame 48/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.1ms\n",
            "video 1/1 (frame 49/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.6ms\n",
            "video 1/1 (frame 50/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.4ms\n",
            "video 1/1 (frame 51/2022) /content/test_yolo.mp4: 384x640 2 twigs, 5.9ms\n",
            "video 1/1 (frame 52/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.8ms\n",
            "video 1/1 (frame 53/2022) /content/test_yolo.mp4: 384x640 2 twigs, 5.8ms\n",
            "video 1/1 (frame 54/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.2ms\n",
            "video 1/1 (frame 55/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.7ms\n",
            "video 1/1 (frame 56/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.4ms\n",
            "video 1/1 (frame 57/2022) /content/test_yolo.mp4: 384x640 3 twigs, 5.8ms\n",
            "video 1/1 (frame 58/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.5ms\n",
            "video 1/1 (frame 59/2022) /content/test_yolo.mp4: 384x640 3 twigs, 5.9ms\n",
            "video 1/1 (frame 60/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.6ms\n",
            "video 1/1 (frame 61/2022) /content/test_yolo.mp4: 384x640 4 twigs, 5.9ms\n",
            "video 1/1 (frame 62/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 63/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 64/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.1ms\n",
            "video 1/1 (frame 65/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.8ms\n",
            "video 1/1 (frame 66/2022) /content/test_yolo.mp4: 384x640 4 twigs, 13.5ms\n",
            "video 1/1 (frame 67/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 68/2022) /content/test_yolo.mp4: 384x640 4 twigs, 15.8ms\n",
            "video 1/1 (frame 69/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 70/2022) /content/test_yolo.mp4: 384x640 4 twigs, 19.7ms\n",
            "video 1/1 (frame 71/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.8ms\n",
            "video 1/1 (frame 72/2022) /content/test_yolo.mp4: 384x640 3 twigs, 13.0ms\n",
            "video 1/1 (frame 73/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.8ms\n",
            "video 1/1 (frame 74/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.8ms\n",
            "video 1/1 (frame 75/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.5ms\n",
            "video 1/1 (frame 76/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 77/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 78/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.2ms\n",
            "video 1/1 (frame 79/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.4ms\n",
            "video 1/1 (frame 80/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.9ms\n",
            "video 1/1 (frame 81/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 82/2022) /content/test_yolo.mp4: 384x640 4 twigs, 15.5ms\n",
            "video 1/1 (frame 83/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.5ms\n",
            "video 1/1 (frame 84/2022) /content/test_yolo.mp4: 384x640 5 twigs, 11.9ms\n",
            "video 1/1 (frame 85/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.8ms\n",
            "video 1/1 (frame 86/2022) /content/test_yolo.mp4: 384x640 5 twigs, 14.3ms\n",
            "video 1/1 (frame 87/2022) /content/test_yolo.mp4: 384x640 6 twigs, 11.3ms\n",
            "video 1/1 (frame 88/2022) /content/test_yolo.mp4: 384x640 6 twigs, 14.3ms\n",
            "video 1/1 (frame 89/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.9ms\n",
            "video 1/1 (frame 90/2022) /content/test_yolo.mp4: 384x640 6 twigs, 18.2ms\n",
            "video 1/1 (frame 91/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 92/2022) /content/test_yolo.mp4: 384x640 6 twigs, 14.6ms\n",
            "video 1/1 (frame 93/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.5ms\n",
            "video 1/1 (frame 94/2022) /content/test_yolo.mp4: 384x640 6 twigs, 16.0ms\n",
            "video 1/1 (frame 95/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.9ms\n",
            "video 1/1 (frame 96/2022) /content/test_yolo.mp4: 384x640 6 twigs, 13.6ms\n",
            "video 1/1 (frame 97/2022) /content/test_yolo.mp4: 384x640 6 twigs, 11.7ms\n",
            "video 1/1 (frame 98/2022) /content/test_yolo.mp4: 384x640 6 twigs, 13.9ms\n",
            "video 1/1 (frame 99/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.6ms\n",
            "video 1/1 (frame 100/2022) /content/test_yolo.mp4: 384x640 6 twigs, 15.4ms\n",
            "video 1/1 (frame 101/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.5ms\n",
            "video 1/1 (frame 102/2022) /content/test_yolo.mp4: 384x640 6 twigs, 15.7ms\n",
            "video 1/1 (frame 103/2022) /content/test_yolo.mp4: 384x640 6 twigs, 11.2ms\n",
            "video 1/1 (frame 104/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.9ms\n",
            "video 1/1 (frame 105/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.8ms\n",
            "video 1/1 (frame 106/2022) /content/test_yolo.mp4: 384x640 6 twigs, 14.2ms\n",
            "video 1/1 (frame 107/2022) /content/test_yolo.mp4: 384x640 6 twigs, 12.2ms\n",
            "video 1/1 (frame 108/2022) /content/test_yolo.mp4: 384x640 6 twigs, 15.5ms\n",
            "video 1/1 (frame 109/2022) /content/test_yolo.mp4: 384x640 6 twigs, 11.7ms\n",
            "video 1/1 (frame 110/2022) /content/test_yolo.mp4: 384x640 6 twigs, 19.0ms\n",
            "video 1/1 (frame 111/2022) /content/test_yolo.mp4: 384x640 5 twigs, 11.7ms\n",
            "video 1/1 (frame 112/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.3ms\n",
            "video 1/1 (frame 113/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.2ms\n",
            "video 1/1 (frame 114/2022) /content/test_yolo.mp4: 384x640 5 twigs, 18.2ms\n",
            "video 1/1 (frame 115/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.4ms\n",
            "video 1/1 (frame 116/2022) /content/test_yolo.mp4: 384x640 5 twigs, 11.3ms\n",
            "video 1/1 (frame 117/2022) /content/test_yolo.mp4: 384x640 5 twigs, 11.8ms\n",
            "video 1/1 (frame 118/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.9ms\n",
            "video 1/1 (frame 119/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.1ms\n",
            "video 1/1 (frame 120/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.1ms\n",
            "video 1/1 (frame 121/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.3ms\n",
            "video 1/1 (frame 122/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.5ms\n",
            "video 1/1 (frame 123/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 124/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 125/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 126/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.0ms\n",
            "video 1/1 (frame 127/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 128/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.5ms\n",
            "video 1/1 (frame 129/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.8ms\n",
            "video 1/1 (frame 130/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 131/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.1ms\n",
            "video 1/1 (frame 132/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.8ms\n",
            "video 1/1 (frame 133/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.6ms\n",
            "video 1/1 (frame 134/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.1ms\n",
            "video 1/1 (frame 135/2022) /content/test_yolo.mp4: 384x640 6 twigs, 5.9ms\n",
            "video 1/1 (frame 136/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.5ms\n",
            "video 1/1 (frame 137/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.8ms\n",
            "video 1/1 (frame 138/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 139/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.7ms\n",
            "video 1/1 (frame 140/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.8ms\n",
            "video 1/1 (frame 141/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.3ms\n",
            "video 1/1 (frame 142/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 143/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.8ms\n",
            "video 1/1 (frame 144/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.5ms\n",
            "video 1/1 (frame 145/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.8ms\n",
            "video 1/1 (frame 146/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.2ms\n",
            "video 1/1 (frame 147/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.7ms\n",
            "video 1/1 (frame 148/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 149/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.6ms\n",
            "video 1/1 (frame 150/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.8ms\n",
            "video 1/1 (frame 151/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.4ms\n",
            "video 1/1 (frame 152/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.6ms\n",
            "video 1/1 (frame 153/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.9ms\n",
            "video 1/1 (frame 154/2022) /content/test_yolo.mp4: 384x640 6 twigs, 39.5ms\n",
            "video 1/1 (frame 155/2022) /content/test_yolo.mp4: 384x640 6 twigs, 32.4ms\n",
            "video 1/1 (frame 156/2022) /content/test_yolo.mp4: 384x640 6 twigs, 21.0ms\n",
            "video 1/1 (frame 157/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.4ms\n",
            "video 1/1 (frame 158/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.5ms\n",
            "video 1/1 (frame 159/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.3ms\n",
            "video 1/1 (frame 160/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 161/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.2ms\n",
            "video 1/1 (frame 162/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.3ms\n",
            "video 1/1 (frame 163/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 164/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 165/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.6ms\n",
            "video 1/1 (frame 166/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.3ms\n",
            "video 1/1 (frame 167/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 168/2022) /content/test_yolo.mp4: 384x640 5 twigs, 40.1ms\n",
            "video 1/1 (frame 169/2022) /content/test_yolo.mp4: 384x640 5 twigs, 16.6ms\n",
            "video 1/1 (frame 170/2022) /content/test_yolo.mp4: 384x640 5 twigs, 17.9ms\n",
            "video 1/1 (frame 171/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.2ms\n",
            "video 1/1 (frame 172/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 173/2022) /content/test_yolo.mp4: 384x640 8 twigs, 6.1ms\n",
            "video 1/1 (frame 174/2022) /content/test_yolo.mp4: 384x640 8 twigs, 8.9ms\n",
            "video 1/1 (frame 175/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.9ms\n",
            "video 1/1 (frame 176/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 177/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.1ms\n",
            "video 1/1 (frame 178/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 179/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.4ms\n",
            "video 1/1 (frame 180/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.6ms\n",
            "video 1/1 (frame 181/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.2ms\n",
            "video 1/1 (frame 182/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 183/2022) /content/test_yolo.mp4: 384x640 6 twigs, 33.8ms\n",
            "video 1/1 (frame 184/2022) /content/test_yolo.mp4: 384x640 6 twigs, 24.2ms\n",
            "video 1/1 (frame 185/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.2ms\n",
            "video 1/1 (frame 186/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 187/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.0ms\n",
            "video 1/1 (frame 188/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.2ms\n",
            "video 1/1 (frame 189/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.4ms\n",
            "video 1/1 (frame 190/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.7ms\n",
            "video 1/1 (frame 191/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.0ms\n",
            "video 1/1 (frame 192/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.6ms\n",
            "video 1/1 (frame 193/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 194/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 195/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.9ms\n",
            "video 1/1 (frame 196/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.3ms\n",
            "video 1/1 (frame 197/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 198/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.8ms\n",
            "video 1/1 (frame 199/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.6ms\n",
            "video 1/1 (frame 200/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.8ms\n",
            "video 1/1 (frame 201/2022) /content/test_yolo.mp4: 384x640 5 twigs, 5.8ms\n",
            "video 1/1 (frame 202/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.4ms\n",
            "video 1/1 (frame 203/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 204/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.6ms\n",
            "video 1/1 (frame 205/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.4ms\n",
            "video 1/1 (frame 206/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.1ms\n",
            "video 1/1 (frame 207/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 208/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.5ms\n",
            "video 1/1 (frame 209/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.8ms\n",
            "video 1/1 (frame 210/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.2ms\n",
            "video 1/1 (frame 211/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 212/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.6ms\n",
            "video 1/1 (frame 213/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.3ms\n",
            "video 1/1 (frame 214/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.8ms\n",
            "video 1/1 (frame 215/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 216/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.2ms\n",
            "video 1/1 (frame 217/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.2ms\n",
            "video 1/1 (frame 218/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 219/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 220/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 221/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 222/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 223/2022) /content/test_yolo.mp4: 384x640 4 twigs, 5.9ms\n",
            "video 1/1 (frame 224/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.3ms\n",
            "video 1/1 (frame 225/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.4ms\n",
            "video 1/1 (frame 226/2022) /content/test_yolo.mp4: 384x640 3 twigs, 21.9ms\n",
            "video 1/1 (frame 227/2022) /content/test_yolo.mp4: 384x640 3 twigs, 14.4ms\n",
            "video 1/1 (frame 228/2022) /content/test_yolo.mp4: 384x640 3 twigs, 20.1ms\n",
            "video 1/1 (frame 229/2022) /content/test_yolo.mp4: 384x640 3 twigs, 25.5ms\n",
            "video 1/1 (frame 230/2022) /content/test_yolo.mp4: 384x640 3 twigs, 19.0ms\n",
            "video 1/1 (frame 231/2022) /content/test_yolo.mp4: 384x640 3 twigs, 32.3ms\n",
            "video 1/1 (frame 232/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.7ms\n",
            "video 1/1 (frame 233/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.5ms\n",
            "video 1/1 (frame 234/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.0ms\n",
            "video 1/1 (frame 235/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.2ms\n",
            "video 1/1 (frame 236/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 237/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.4ms\n",
            "video 1/1 (frame 238/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 239/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 240/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.9ms\n",
            "video 1/1 (frame 241/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 242/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 243/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.3ms\n",
            "video 1/1 (frame 244/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.6ms\n",
            "video 1/1 (frame 245/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.2ms\n",
            "video 1/1 (frame 246/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.3ms\n",
            "video 1/1 (frame 247/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 248/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.6ms\n",
            "video 1/1 (frame 249/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.6ms\n",
            "video 1/1 (frame 250/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 251/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.3ms\n",
            "video 1/1 (frame 252/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 253/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 254/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.2ms\n",
            "video 1/1 (frame 255/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 256/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.2ms\n",
            "video 1/1 (frame 257/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 258/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.4ms\n",
            "video 1/1 (frame 259/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 260/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 261/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 262/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.0ms\n",
            "video 1/1 (frame 263/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 264/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.8ms\n",
            "video 1/1 (frame 265/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 266/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 267/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.8ms\n",
            "video 1/1 (frame 268/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.9ms\n",
            "video 1/1 (frame 269/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.9ms\n",
            "video 1/1 (frame 270/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 271/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.8ms\n",
            "video 1/1 (frame 272/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 273/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.6ms\n",
            "video 1/1 (frame 274/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.8ms\n",
            "video 1/1 (frame 275/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.9ms\n",
            "video 1/1 (frame 276/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.2ms\n",
            "video 1/1 (frame 277/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 278/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.9ms\n",
            "video 1/1 (frame 279/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.3ms\n",
            "video 1/1 (frame 280/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 281/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.3ms\n",
            "video 1/1 (frame 282/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 283/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.2ms\n",
            "video 1/1 (frame 284/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 285/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 286/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 287/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.5ms\n",
            "video 1/1 (frame 288/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 289/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.8ms\n",
            "video 1/1 (frame 290/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 291/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 292/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 293/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.0ms\n",
            "video 1/1 (frame 294/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 295/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 296/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.3ms\n",
            "video 1/1 (frame 297/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.9ms\n",
            "video 1/1 (frame 298/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 299/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.8ms\n",
            "video 1/1 (frame 300/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.8ms\n",
            "video 1/1 (frame 301/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 302/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 303/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.8ms\n",
            "video 1/1 (frame 304/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 305/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.6ms\n",
            "video 1/1 (frame 306/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.3ms\n",
            "video 1/1 (frame 307/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.7ms\n",
            "video 1/1 (frame 308/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.3ms\n",
            "video 1/1 (frame 309/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.7ms\n",
            "video 1/1 (frame 310/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 311/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.7ms\n",
            "video 1/1 (frame 312/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.7ms\n",
            "video 1/1 (frame 313/2022) /content/test_yolo.mp4: 384x640 3 twigs, 14.7ms\n",
            "video 1/1 (frame 314/2022) /content/test_yolo.mp4: 384x640 3 twigs, 11.8ms\n",
            "video 1/1 (frame 315/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 316/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.8ms\n",
            "video 1/1 (frame 317/2022) /content/test_yolo.mp4: 384x640 3 twigs, 15.1ms\n",
            "video 1/1 (frame 318/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 319/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 320/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.8ms\n",
            "video 1/1 (frame 321/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.1ms\n",
            "video 1/1 (frame 322/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 323/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.4ms\n",
            "video 1/1 (frame 324/2022) /content/test_yolo.mp4: 384x640 4 twigs, 13.5ms\n",
            "video 1/1 (frame 325/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 326/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 327/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.3ms\n",
            "video 1/1 (frame 328/2022) /content/test_yolo.mp4: 384x640 4 twigs, 17.5ms\n",
            "video 1/1 (frame 329/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.4ms\n",
            "video 1/1 (frame 330/2022) /content/test_yolo.mp4: 384x640 4 twigs, 31.7ms\n",
            "video 1/1 (frame 331/2022) /content/test_yolo.mp4: 384x640 4 twigs, 19.3ms\n",
            "video 1/1 (frame 332/2022) /content/test_yolo.mp4: 384x640 4 twigs, 19.7ms\n",
            "video 1/1 (frame 333/2022) /content/test_yolo.mp4: 384x640 5 twigs, 22.2ms\n",
            "video 1/1 (frame 334/2022) /content/test_yolo.mp4: 384x640 5 twigs, 47.8ms\n",
            "video 1/1 (frame 335/2022) /content/test_yolo.mp4: 384x640 4 twigs, 34.9ms\n",
            "video 1/1 (frame 336/2022) /content/test_yolo.mp4: 384x640 4 twigs, 48.6ms\n",
            "video 1/1 (frame 337/2022) /content/test_yolo.mp4: 384x640 4 twigs, 22.2ms\n",
            "video 1/1 (frame 338/2022) /content/test_yolo.mp4: 384x640 4 twigs, 16.6ms\n",
            "video 1/1 (frame 339/2022) /content/test_yolo.mp4: 384x640 4 twigs, 48.8ms\n",
            "video 1/1 (frame 340/2022) /content/test_yolo.mp4: 384x640 4 twigs, 26.4ms\n",
            "video 1/1 (frame 341/2022) /content/test_yolo.mp4: 384x640 5 twigs, 41.2ms\n",
            "video 1/1 (frame 342/2022) /content/test_yolo.mp4: 384x640 5 twigs, 28.2ms\n",
            "video 1/1 (frame 343/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.5ms\n",
            "video 1/1 (frame 344/2022) /content/test_yolo.mp4: 384x640 5 twigs, 16.9ms\n",
            "video 1/1 (frame 345/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.8ms\n",
            "video 1/1 (frame 346/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 347/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 348/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 349/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 350/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.9ms\n",
            "video 1/1 (frame 351/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.6ms\n",
            "video 1/1 (frame 352/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.4ms\n",
            "video 1/1 (frame 353/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.1ms\n",
            "video 1/1 (frame 354/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.3ms\n",
            "video 1/1 (frame 355/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.1ms\n",
            "video 1/1 (frame 356/2022) /content/test_yolo.mp4: 384x640 3 twigs, 14.1ms\n",
            "video 1/1 (frame 357/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.8ms\n",
            "video 1/1 (frame 358/2022) /content/test_yolo.mp4: 384x640 5 twigs, 14.4ms\n",
            "video 1/1 (frame 359/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.4ms\n",
            "video 1/1 (frame 360/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.6ms\n",
            "video 1/1 (frame 361/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.2ms\n",
            "video 1/1 (frame 362/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.5ms\n",
            "video 1/1 (frame 363/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.7ms\n",
            "video 1/1 (frame 364/2022) /content/test_yolo.mp4: 384x640 4 twigs, 17.4ms\n",
            "video 1/1 (frame 365/2022) /content/test_yolo.mp4: 384x640 3 twigs, 11.3ms\n",
            "video 1/1 (frame 366/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.8ms\n",
            "video 1/1 (frame 367/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.5ms\n",
            "video 1/1 (frame 368/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.8ms\n",
            "video 1/1 (frame 369/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.5ms\n",
            "video 1/1 (frame 370/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.4ms\n",
            "video 1/1 (frame 371/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 372/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 373/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.5ms\n",
            "video 1/1 (frame 374/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.2ms\n",
            "video 1/1 (frame 375/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.6ms\n",
            "video 1/1 (frame 376/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.2ms\n",
            "video 1/1 (frame 377/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.9ms\n",
            "video 1/1 (frame 378/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.2ms\n",
            "video 1/1 (frame 379/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.6ms\n",
            "video 1/1 (frame 380/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.2ms\n",
            "video 1/1 (frame 381/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.1ms\n",
            "video 1/1 (frame 382/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.3ms\n",
            "video 1/1 (frame 383/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.6ms\n",
            "video 1/1 (frame 384/2022) /content/test_yolo.mp4: 384x640 2 twigs, 14.2ms\n",
            "video 1/1 (frame 385/2022) /content/test_yolo.mp4: 384x640 2 twigs, 20.0ms\n",
            "video 1/1 (frame 386/2022) /content/test_yolo.mp4: 384x640 2 twigs, 23.7ms\n",
            "video 1/1 (frame 387/2022) /content/test_yolo.mp4: 384x640 3 twigs, 20.1ms\n",
            "video 1/1 (frame 388/2022) /content/test_yolo.mp4: 384x640 2 twigs, 28.3ms\n",
            "video 1/1 (frame 389/2022) /content/test_yolo.mp4: 384x640 3 twigs, 21.2ms\n",
            "video 1/1 (frame 390/2022) /content/test_yolo.mp4: 384x640 3 twigs, 46.9ms\n",
            "video 1/1 (frame 391/2022) /content/test_yolo.mp4: 384x640 4 twigs, 20.6ms\n",
            "video 1/1 (frame 392/2022) /content/test_yolo.mp4: 384x640 4 twigs, 35.8ms\n",
            "video 1/1 (frame 393/2022) /content/test_yolo.mp4: 384x640 4 twigs, 23.5ms\n",
            "video 1/1 (frame 394/2022) /content/test_yolo.mp4: 384x640 4 twigs, 38.6ms\n",
            "video 1/1 (frame 395/2022) /content/test_yolo.mp4: 384x640 5 twigs, 22.1ms\n",
            "video 1/1 (frame 396/2022) /content/test_yolo.mp4: 384x640 5 twigs, 35.2ms\n",
            "video 1/1 (frame 397/2022) /content/test_yolo.mp4: 384x640 4 twigs, 18.8ms\n",
            "video 1/1 (frame 398/2022) /content/test_yolo.mp4: 384x640 4 twigs, 37.2ms\n",
            "video 1/1 (frame 399/2022) /content/test_yolo.mp4: 384x640 4 twigs, 19.1ms\n",
            "video 1/1 (frame 400/2022) /content/test_yolo.mp4: 384x640 4 twigs, 40.1ms\n",
            "video 1/1 (frame 401/2022) /content/test_yolo.mp4: 384x640 4 twigs, 16.7ms\n",
            "video 1/1 (frame 402/2022) /content/test_yolo.mp4: 384x640 4 twigs, 38.9ms\n",
            "video 1/1 (frame 403/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.9ms\n",
            "video 1/1 (frame 404/2022) /content/test_yolo.mp4: 384x640 4 twigs, 15.1ms\n",
            "video 1/1 (frame 405/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.7ms\n",
            "video 1/1 (frame 406/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.6ms\n",
            "video 1/1 (frame 407/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.0ms\n",
            "video 1/1 (frame 408/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 409/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 410/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 411/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 412/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 413/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 414/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 415/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.9ms\n",
            "video 1/1 (frame 416/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 417/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.8ms\n",
            "video 1/1 (frame 418/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.2ms\n",
            "video 1/1 (frame 419/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 420/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.1ms\n",
            "video 1/1 (frame 421/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.9ms\n",
            "video 1/1 (frame 422/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.4ms\n",
            "video 1/1 (frame 423/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 424/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.0ms\n",
            "video 1/1 (frame 425/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 426/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 427/2022) /content/test_yolo.mp4: 384x640 5 twigs, 17.4ms\n",
            "video 1/1 (frame 428/2022) /content/test_yolo.mp4: 384x640 5 twigs, 18.5ms\n",
            "video 1/1 (frame 429/2022) /content/test_yolo.mp4: 384x640 5 twigs, 21.2ms\n",
            "video 1/1 (frame 430/2022) /content/test_yolo.mp4: 384x640 5 twigs, 45.9ms\n",
            "video 1/1 (frame 431/2022) /content/test_yolo.mp4: 384x640 5 twigs, 24.2ms\n",
            "video 1/1 (frame 432/2022) /content/test_yolo.mp4: 384x640 5 twigs, 33.8ms\n",
            "video 1/1 (frame 433/2022) /content/test_yolo.mp4: 384x640 5 twigs, 22.5ms\n",
            "video 1/1 (frame 434/2022) /content/test_yolo.mp4: 384x640 5 twigs, 14.7ms\n",
            "video 1/1 (frame 435/2022) /content/test_yolo.mp4: 384x640 5 twigs, 22.8ms\n",
            "video 1/1 (frame 436/2022) /content/test_yolo.mp4: 384x640 5 twigs, 29.7ms\n",
            "video 1/1 (frame 437/2022) /content/test_yolo.mp4: 384x640 5 twigs, 21.7ms\n",
            "video 1/1 (frame 438/2022) /content/test_yolo.mp4: 384x640 5 twigs, 34.1ms\n",
            "video 1/1 (frame 439/2022) /content/test_yolo.mp4: 384x640 5 twigs, 34.0ms\n",
            "video 1/1 (frame 440/2022) /content/test_yolo.mp4: 384x640 5 twigs, 31.9ms\n",
            "video 1/1 (frame 441/2022) /content/test_yolo.mp4: 384x640 5 twigs, 25.8ms\n",
            "video 1/1 (frame 442/2022) /content/test_yolo.mp4: 384x640 5 twigs, 34.4ms\n",
            "video 1/1 (frame 443/2022) /content/test_yolo.mp4: 384x640 5 twigs, 21.6ms\n",
            "video 1/1 (frame 444/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.0ms\n",
            "video 1/1 (frame 445/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.4ms\n",
            "video 1/1 (frame 446/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 447/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.7ms\n",
            "video 1/1 (frame 448/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.9ms\n",
            "video 1/1 (frame 449/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.4ms\n",
            "video 1/1 (frame 450/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.7ms\n",
            "video 1/1 (frame 451/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.6ms\n",
            "video 1/1 (frame 452/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.2ms\n",
            "video 1/1 (frame 453/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.1ms\n",
            "video 1/1 (frame 454/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.4ms\n",
            "video 1/1 (frame 455/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.4ms\n",
            "video 1/1 (frame 456/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.6ms\n",
            "video 1/1 (frame 457/2022) /content/test_yolo.mp4: 384x640 5 twigs, 16.6ms\n",
            "video 1/1 (frame 458/2022) /content/test_yolo.mp4: 384x640 5 twigs, 14.0ms\n",
            "video 1/1 (frame 459/2022) /content/test_yolo.mp4: 384x640 7 twigs, 17.1ms\n",
            "video 1/1 (frame 460/2022) /content/test_yolo.mp4: 384x640 7 twigs, 17.5ms\n",
            "video 1/1 (frame 461/2022) /content/test_yolo.mp4: 384x640 5 twigs, 23.2ms\n",
            "video 1/1 (frame 462/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.5ms\n",
            "video 1/1 (frame 463/2022) /content/test_yolo.mp4: 384x640 4 twigs, 24.3ms\n",
            "video 1/1 (frame 464/2022) /content/test_yolo.mp4: 384x640 4 twigs, 14.4ms\n",
            "video 1/1 (frame 465/2022) /content/test_yolo.mp4: 384x640 5 twigs, 21.1ms\n",
            "video 1/1 (frame 466/2022) /content/test_yolo.mp4: 384x640 5 twigs, 14.7ms\n",
            "video 1/1 (frame 467/2022) /content/test_yolo.mp4: 384x640 4 twigs, 20.5ms\n",
            "video 1/1 (frame 468/2022) /content/test_yolo.mp4: 384x640 4 twigs, 14.3ms\n",
            "video 1/1 (frame 469/2022) /content/test_yolo.mp4: 384x640 5 twigs, 21.1ms\n",
            "video 1/1 (frame 470/2022) /content/test_yolo.mp4: 384x640 5 twigs, 26.6ms\n",
            "video 1/1 (frame 471/2022) /content/test_yolo.mp4: 384x640 4 twigs, 20.7ms\n",
            "video 1/1 (frame 472/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.7ms\n",
            "video 1/1 (frame 473/2022) /content/test_yolo.mp4: 384x640 5 twigs, 23.2ms\n",
            "video 1/1 (frame 474/2022) /content/test_yolo.mp4: 384x640 5 twigs, 37.2ms\n",
            "video 1/1 (frame 475/2022) /content/test_yolo.mp4: 384x640 5 twigs, 20.9ms\n",
            "video 1/1 (frame 476/2022) /content/test_yolo.mp4: 384x640 5 twigs, 39.2ms\n",
            "video 1/1 (frame 477/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.9ms\n",
            "video 1/1 (frame 478/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.3ms\n",
            "video 1/1 (frame 479/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.1ms\n",
            "video 1/1 (frame 480/2022) /content/test_yolo.mp4: 384x640 5 twigs, 18.3ms\n",
            "video 1/1 (frame 481/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.6ms\n",
            "video 1/1 (frame 482/2022) /content/test_yolo.mp4: 384x640 6 twigs, 17.6ms\n",
            "video 1/1 (frame 483/2022) /content/test_yolo.mp4: 384x640 6 twigs, 12.5ms\n",
            "video 1/1 (frame 484/2022) /content/test_yolo.mp4: 384x640 6 twigs, 17.6ms\n",
            "video 1/1 (frame 485/2022) /content/test_yolo.mp4: 384x640 6 twigs, 12.5ms\n",
            "video 1/1 (frame 486/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.4ms\n",
            "video 1/1 (frame 487/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.8ms\n",
            "video 1/1 (frame 488/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 489/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.5ms\n",
            "video 1/1 (frame 490/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.5ms\n",
            "video 1/1 (frame 491/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.4ms\n",
            "video 1/1 (frame 492/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.8ms\n",
            "video 1/1 (frame 493/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.6ms\n",
            "video 1/1 (frame 494/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.2ms\n",
            "video 1/1 (frame 495/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.2ms\n",
            "video 1/1 (frame 496/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.9ms\n",
            "video 1/1 (frame 497/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.9ms\n",
            "video 1/1 (frame 498/2022) /content/test_yolo.mp4: 384x640 7 twigs, 10.9ms\n",
            "video 1/1 (frame 499/2022) /content/test_yolo.mp4: 384x640 8 twigs, 7.1ms\n",
            "video 1/1 (frame 500/2022) /content/test_yolo.mp4: 384x640 8 twigs, 9.8ms\n",
            "video 1/1 (frame 501/2022) /content/test_yolo.mp4: 384x640 8 twigs, 7.2ms\n",
            "video 1/1 (frame 502/2022) /content/test_yolo.mp4: 384x640 8 twigs, 8.8ms\n",
            "video 1/1 (frame 503/2022) /content/test_yolo.mp4: 384x640 9 twigs, 7.0ms\n",
            "video 1/1 (frame 504/2022) /content/test_yolo.mp4: 384x640 9 twigs, 8.7ms\n",
            "video 1/1 (frame 505/2022) /content/test_yolo.mp4: 384x640 8 twigs, 6.7ms\n",
            "video 1/1 (frame 506/2022) /content/test_yolo.mp4: 384x640 8 twigs, 8.6ms\n",
            "video 1/1 (frame 507/2022) /content/test_yolo.mp4: 384x640 8 twigs, 6.9ms\n",
            "video 1/1 (frame 508/2022) /content/test_yolo.mp4: 384x640 8 twigs, 9.4ms\n",
            "video 1/1 (frame 509/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.5ms\n",
            "video 1/1 (frame 510/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.7ms\n",
            "video 1/1 (frame 511/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.6ms\n",
            "video 1/1 (frame 512/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.4ms\n",
            "video 1/1 (frame 513/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.0ms\n",
            "video 1/1 (frame 514/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.8ms\n",
            "video 1/1 (frame 515/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.9ms\n",
            "video 1/1 (frame 516/2022) /content/test_yolo.mp4: 384x640 7 twigs, 10.0ms\n",
            "video 1/1 (frame 517/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.3ms\n",
            "video 1/1 (frame 518/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.8ms\n",
            "video 1/1 (frame 519/2022) /content/test_yolo.mp4: 384x640 7 twigs, 13.1ms\n",
            "video 1/1 (frame 520/2022) /content/test_yolo.mp4: 384x640 7 twigs, 14.7ms\n",
            "video 1/1 (frame 521/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.4ms\n",
            "video 1/1 (frame 522/2022) /content/test_yolo.mp4: 384x640 6 twigs, 14.6ms\n",
            "video 1/1 (frame 523/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.3ms\n",
            "video 1/1 (frame 524/2022) /content/test_yolo.mp4: 384x640 6 twigs, 22.7ms\n",
            "video 1/1 (frame 525/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.8ms\n",
            "video 1/1 (frame 526/2022) /content/test_yolo.mp4: 384x640 6 twigs, 18.1ms\n",
            "video 1/1 (frame 527/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.7ms\n",
            "video 1/1 (frame 528/2022) /content/test_yolo.mp4: 384x640 6 twigs, 20.4ms\n",
            "video 1/1 (frame 529/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.1ms\n",
            "video 1/1 (frame 530/2022) /content/test_yolo.mp4: 384x640 6 twigs, 17.7ms\n",
            "video 1/1 (frame 531/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.8ms\n",
            "video 1/1 (frame 532/2022) /content/test_yolo.mp4: 384x640 6 twigs, 19.6ms\n",
            "video 1/1 (frame 533/2022) /content/test_yolo.mp4: 384x640 6 twigs, 13.1ms\n",
            "video 1/1 (frame 534/2022) /content/test_yolo.mp4: 384x640 6 twigs, 16.4ms\n",
            "video 1/1 (frame 535/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.0ms\n",
            "video 1/1 (frame 536/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.5ms\n",
            "video 1/1 (frame 537/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 538/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 539/2022) /content/test_yolo.mp4: 384x640 6 twigs, 5.9ms\n",
            "video 1/1 (frame 540/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.8ms\n",
            "video 1/1 (frame 541/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.0ms\n",
            "video 1/1 (frame 542/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 543/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.1ms\n",
            "video 1/1 (frame 544/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 545/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.8ms\n",
            "video 1/1 (frame 546/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.5ms\n",
            "video 1/1 (frame 547/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.2ms\n",
            "video 1/1 (frame 548/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.0ms\n",
            "video 1/1 (frame 549/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.3ms\n",
            "video 1/1 (frame 550/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 551/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.2ms\n",
            "video 1/1 (frame 552/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 553/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.3ms\n",
            "video 1/1 (frame 554/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.8ms\n",
            "video 1/1 (frame 555/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 556/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.8ms\n",
            "video 1/1 (frame 557/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 558/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.3ms\n",
            "video 1/1 (frame 559/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.0ms\n",
            "video 1/1 (frame 560/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 561/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.5ms\n",
            "video 1/1 (frame 562/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.8ms\n",
            "video 1/1 (frame 563/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.3ms\n",
            "video 1/1 (frame 564/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.6ms\n",
            "video 1/1 (frame 565/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.9ms\n",
            "video 1/1 (frame 566/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 567/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.4ms\n",
            "video 1/1 (frame 568/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.1ms\n",
            "video 1/1 (frame 569/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.1ms\n",
            "video 1/1 (frame 570/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.7ms\n",
            "video 1/1 (frame 571/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 572/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.8ms\n",
            "video 1/1 (frame 573/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.0ms\n",
            "video 1/1 (frame 574/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 575/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.4ms\n",
            "video 1/1 (frame 576/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.3ms\n",
            "video 1/1 (frame 577/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 578/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.7ms\n",
            "video 1/1 (frame 579/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 580/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 581/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 582/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 583/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 584/2022) /content/test_yolo.mp4: 384x640 5 twigs, 20.8ms\n",
            "video 1/1 (frame 585/2022) /content/test_yolo.mp4: 384x640 5 twigs, 17.6ms\n",
            "video 1/1 (frame 586/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.6ms\n",
            "video 1/1 (frame 587/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.0ms\n",
            "video 1/1 (frame 588/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 589/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.0ms\n",
            "video 1/1 (frame 590/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 591/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 592/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.8ms\n",
            "video 1/1 (frame 593/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 594/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 595/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 596/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 597/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 598/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.6ms\n",
            "video 1/1 (frame 599/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.1ms\n",
            "video 1/1 (frame 600/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.3ms\n",
            "video 1/1 (frame 601/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.1ms\n",
            "video 1/1 (frame 602/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.8ms\n",
            "video 1/1 (frame 603/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.9ms\n",
            "video 1/1 (frame 604/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.4ms\n",
            "video 1/1 (frame 605/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.3ms\n",
            "video 1/1 (frame 606/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.3ms\n",
            "video 1/1 (frame 607/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.8ms\n",
            "video 1/1 (frame 608/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.3ms\n",
            "video 1/1 (frame 609/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.4ms\n",
            "video 1/1 (frame 610/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.3ms\n",
            "video 1/1 (frame 611/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.1ms\n",
            "video 1/1 (frame 612/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.5ms\n",
            "video 1/1 (frame 613/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.0ms\n",
            "video 1/1 (frame 614/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 615/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 616/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 617/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.0ms\n",
            "video 1/1 (frame 618/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.7ms\n",
            "video 1/1 (frame 619/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 620/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 621/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 622/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.2ms\n",
            "video 1/1 (frame 623/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.3ms\n",
            "video 1/1 (frame 624/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 625/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.6ms\n",
            "video 1/1 (frame 626/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 627/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 628/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 629/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.2ms\n",
            "video 1/1 (frame 630/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 631/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 632/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.9ms\n",
            "video 1/1 (frame 633/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 634/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.2ms\n",
            "video 1/1 (frame 635/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 636/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.7ms\n",
            "video 1/1 (frame 637/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 638/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.2ms\n",
            "video 1/1 (frame 639/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.7ms\n",
            "video 1/1 (frame 640/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.7ms\n",
            "video 1/1 (frame 641/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.1ms\n",
            "video 1/1 (frame 642/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 643/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.9ms\n",
            "video 1/1 (frame 644/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.6ms\n",
            "video 1/1 (frame 645/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.0ms\n",
            "video 1/1 (frame 646/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 647/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.2ms\n",
            "video 1/1 (frame 648/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 649/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 650/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 651/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.9ms\n",
            "video 1/1 (frame 652/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.5ms\n",
            "video 1/1 (frame 653/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.9ms\n",
            "video 1/1 (frame 654/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 655/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 656/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.3ms\n",
            "video 1/1 (frame 657/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.5ms\n",
            "video 1/1 (frame 658/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.4ms\n",
            "video 1/1 (frame 659/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 660/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.7ms\n",
            "video 1/1 (frame 661/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 662/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 663/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.3ms\n",
            "video 1/1 (frame 664/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.8ms\n",
            "video 1/1 (frame 665/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.0ms\n",
            "video 1/1 (frame 666/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.7ms\n",
            "video 1/1 (frame 667/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.2ms\n",
            "video 1/1 (frame 668/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.5ms\n",
            "video 1/1 (frame 669/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 670/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.5ms\n",
            "video 1/1 (frame 671/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.7ms\n",
            "video 1/1 (frame 672/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.4ms\n",
            "video 1/1 (frame 673/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.9ms\n",
            "video 1/1 (frame 674/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.8ms\n",
            "video 1/1 (frame 675/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.8ms\n",
            "video 1/1 (frame 676/2022) /content/test_yolo.mp4: 384x640 7 twigs, 10.4ms\n",
            "video 1/1 (frame 677/2022) /content/test_yolo.mp4: 384x640 7 twigs, 5.9ms\n",
            "video 1/1 (frame 678/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.6ms\n",
            "video 1/1 (frame 679/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.6ms\n",
            "video 1/1 (frame 680/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.4ms\n",
            "video 1/1 (frame 681/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.0ms\n",
            "video 1/1 (frame 682/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 683/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.6ms\n",
            "video 1/1 (frame 684/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.1ms\n",
            "video 1/1 (frame 685/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.9ms\n",
            "video 1/1 (frame 686/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.1ms\n",
            "video 1/1 (frame 687/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.5ms\n",
            "video 1/1 (frame 688/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 689/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.9ms\n",
            "video 1/1 (frame 690/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.0ms\n",
            "video 1/1 (frame 691/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.3ms\n",
            "video 1/1 (frame 692/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.2ms\n",
            "video 1/1 (frame 693/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.8ms\n",
            "video 1/1 (frame 694/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.6ms\n",
            "video 1/1 (frame 695/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.1ms\n",
            "video 1/1 (frame 696/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.1ms\n",
            "video 1/1 (frame 697/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.5ms\n",
            "video 1/1 (frame 698/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.8ms\n",
            "video 1/1 (frame 699/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.9ms\n",
            "video 1/1 (frame 700/2022) /content/test_yolo.mp4: 384x640 7 twigs, 10.8ms\n",
            "video 1/1 (frame 701/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.6ms\n",
            "video 1/1 (frame 702/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.4ms\n",
            "video 1/1 (frame 703/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.5ms\n",
            "video 1/1 (frame 704/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.1ms\n",
            "video 1/1 (frame 705/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.2ms\n",
            "video 1/1 (frame 706/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.1ms\n",
            "video 1/1 (frame 707/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.5ms\n",
            "video 1/1 (frame 708/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.3ms\n",
            "video 1/1 (frame 709/2022) /content/test_yolo.mp4: 384x640 7 twigs, 7.1ms\n",
            "video 1/1 (frame 710/2022) /content/test_yolo.mp4: 384x640 7 twigs, 10.3ms\n",
            "video 1/1 (frame 711/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.5ms\n",
            "video 1/1 (frame 712/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.8ms\n",
            "video 1/1 (frame 713/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.6ms\n",
            "video 1/1 (frame 714/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 715/2022) /content/test_yolo.mp4: 384x640 7 twigs, 9.7ms\n",
            "video 1/1 (frame 716/2022) /content/test_yolo.mp4: 384x640 7 twigs, 19.2ms\n",
            "video 1/1 (frame 717/2022) /content/test_yolo.mp4: 384x640 6 twigs, 16.3ms\n",
            "video 1/1 (frame 718/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.1ms\n",
            "video 1/1 (frame 719/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.6ms\n",
            "video 1/1 (frame 720/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.2ms\n",
            "video 1/1 (frame 721/2022) /content/test_yolo.mp4: 384x640 6 twigs, 11.5ms\n",
            "video 1/1 (frame 722/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.0ms\n",
            "video 1/1 (frame 723/2022) /content/test_yolo.mp4: 384x640 6 twigs, 11.0ms\n",
            "video 1/1 (frame 724/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.7ms\n",
            "video 1/1 (frame 725/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.3ms\n",
            "video 1/1 (frame 726/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 727/2022) /content/test_yolo.mp4: 384x640 6 twigs, 14.1ms\n",
            "video 1/1 (frame 728/2022) /content/test_yolo.mp4: 384x640 6 twigs, 19.1ms\n",
            "video 1/1 (frame 729/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.5ms\n",
            "video 1/1 (frame 730/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.0ms\n",
            "video 1/1 (frame 731/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.3ms\n",
            "video 1/1 (frame 732/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.0ms\n",
            "video 1/1 (frame 733/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.8ms\n",
            "video 1/1 (frame 734/2022) /content/test_yolo.mp4: 384x640 4 twigs, 14.1ms\n",
            "video 1/1 (frame 735/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 736/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 737/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 738/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 739/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.7ms\n",
            "video 1/1 (frame 740/2022) /content/test_yolo.mp4: 384x640 4 twigs, 59.3ms\n",
            "video 1/1 (frame 741/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 742/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.6ms\n",
            "video 1/1 (frame 743/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 744/2022) /content/test_yolo.mp4: 384x640 4 twigs, 13.0ms\n",
            "video 1/1 (frame 745/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.1ms\n",
            "video 1/1 (frame 746/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 747/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.3ms\n",
            "video 1/1 (frame 748/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 749/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.5ms\n",
            "video 1/1 (frame 750/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.9ms\n",
            "video 1/1 (frame 751/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 752/2022) /content/test_yolo.mp4: 384x640 5 twigs, 21.3ms\n",
            "video 1/1 (frame 753/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 754/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.2ms\n",
            "video 1/1 (frame 755/2022) /content/test_yolo.mp4: 384x640 5 twigs, 11.0ms\n",
            "video 1/1 (frame 756/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.5ms\n",
            "video 1/1 (frame 757/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.8ms\n",
            "video 1/1 (frame 758/2022) /content/test_yolo.mp4: 384x640 5 twigs, 13.4ms\n",
            "video 1/1 (frame 759/2022) /content/test_yolo.mp4: 384x640 5 twigs, 11.1ms\n",
            "video 1/1 (frame 760/2022) /content/test_yolo.mp4: 384x640 5 twigs, 17.2ms\n",
            "video 1/1 (frame 761/2022) /content/test_yolo.mp4: 384x640 1 plastic, 5 twigs, 11.8ms\n",
            "video 1/1 (frame 762/2022) /content/test_yolo.mp4: 384x640 1 plastic, 5 twigs, 8.3ms\n",
            "video 1/1 (frame 763/2022) /content/test_yolo.mp4: 384x640 7 twigs, 6.4ms\n",
            "video 1/1 (frame 764/2022) /content/test_yolo.mp4: 384x640 7 twigs, 8.0ms\n",
            "video 1/1 (frame 765/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.4ms\n",
            "video 1/1 (frame 766/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.8ms\n",
            "video 1/1 (frame 767/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.1ms\n",
            "video 1/1 (frame 768/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.5ms\n",
            "video 1/1 (frame 769/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.7ms\n",
            "video 1/1 (frame 770/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 771/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.2ms\n",
            "video 1/1 (frame 772/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.0ms\n",
            "video 1/1 (frame 773/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 774/2022) /content/test_yolo.mp4: 384x640 6 twigs, 10.1ms\n",
            "video 1/1 (frame 775/2022) /content/test_yolo.mp4: 384x640 6 twigs, 6.0ms\n",
            "video 1/1 (frame 776/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.5ms\n",
            "video 1/1 (frame 777/2022) /content/test_yolo.mp4: 384x640 6 twigs, 9.5ms\n",
            "video 1/1 (frame 778/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.4ms\n",
            "video 1/1 (frame 779/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.1ms\n",
            "video 1/1 (frame 780/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.9ms\n",
            "video 1/1 (frame 781/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.1ms\n",
            "video 1/1 (frame 782/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.6ms\n",
            "video 1/1 (frame 783/2022) /content/test_yolo.mp4: 384x640 6 twigs, 7.1ms\n",
            "video 1/1 (frame 784/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.7ms\n",
            "video 1/1 (frame 785/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.5ms\n",
            "video 1/1 (frame 786/2022) /content/test_yolo.mp4: 384x640 6 twigs, 8.2ms\n",
            "video 1/1 (frame 787/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.0ms\n",
            "video 1/1 (frame 788/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 789/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.0ms\n",
            "video 1/1 (frame 790/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 791/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 792/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 793/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.3ms\n",
            "video 1/1 (frame 794/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 795/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.9ms\n",
            "video 1/1 (frame 796/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.7ms\n",
            "video 1/1 (frame 797/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.2ms\n",
            "video 1/1 (frame 798/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 799/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 800/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 801/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.4ms\n",
            "video 1/1 (frame 802/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.8ms\n",
            "video 1/1 (frame 803/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.3ms\n",
            "video 1/1 (frame 804/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.9ms\n",
            "video 1/1 (frame 805/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.1ms\n",
            "video 1/1 (frame 806/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 807/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 808/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 809/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.2ms\n",
            "video 1/1 (frame 810/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 811/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 812/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 813/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.4ms\n",
            "video 1/1 (frame 814/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 815/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 816/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.5ms\n",
            "video 1/1 (frame 817/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 818/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 819/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 820/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 821/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 822/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.4ms\n",
            "video 1/1 (frame 823/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.3ms\n",
            "video 1/1 (frame 824/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.1ms\n",
            "video 1/1 (frame 825/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 826/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 827/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 828/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.8ms\n",
            "video 1/1 (frame 829/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 830/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.7ms\n",
            "video 1/1 (frame 831/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.7ms\n",
            "video 1/1 (frame 832/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.3ms\n",
            "video 1/1 (frame 833/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 834/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.2ms\n",
            "video 1/1 (frame 835/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.4ms\n",
            "video 1/1 (frame 836/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 837/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.2ms\n",
            "video 1/1 (frame 838/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 839/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.8ms\n",
            "video 1/1 (frame 840/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 841/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 842/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 843/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.4ms\n",
            "video 1/1 (frame 844/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.8ms\n",
            "video 1/1 (frame 845/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.8ms\n",
            "video 1/1 (frame 846/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.2ms\n",
            "video 1/1 (frame 847/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.5ms\n",
            "video 1/1 (frame 848/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.6ms\n",
            "video 1/1 (frame 849/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 850/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 851/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.5ms\n",
            "video 1/1 (frame 852/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.1ms\n",
            "video 1/1 (frame 853/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.2ms\n",
            "video 1/1 (frame 854/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.0ms\n",
            "video 1/1 (frame 855/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.4ms\n",
            "video 1/1 (frame 856/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.8ms\n",
            "video 1/1 (frame 857/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 858/2022) /content/test_yolo.mp4: 384x640 5 twigs, 12.5ms\n",
            "video 1/1 (frame 859/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.8ms\n",
            "video 1/1 (frame 860/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.5ms\n",
            "video 1/1 (frame 861/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.6ms\n",
            "video 1/1 (frame 862/2022) /content/test_yolo.mp4: 384x640 5 twigs, 10.6ms\n",
            "video 1/1 (frame 863/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 864/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 865/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.0ms\n",
            "video 1/1 (frame 866/2022) /content/test_yolo.mp4: 384x640 5 twigs, 9.9ms\n",
            "video 1/1 (frame 867/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.2ms\n",
            "video 1/1 (frame 868/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.7ms\n",
            "video 1/1 (frame 869/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 870/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.6ms\n",
            "video 1/1 (frame 871/2022) /content/test_yolo.mp4: 384x640 5 twigs, 6.1ms\n",
            "video 1/1 (frame 872/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.0ms\n",
            "video 1/1 (frame 873/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.8ms\n",
            "video 1/1 (frame 874/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 875/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 876/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.6ms\n",
            "video 1/1 (frame 877/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.6ms\n",
            "video 1/1 (frame 878/2022) /content/test_yolo.mp4: 384x640 4 twigs, 14.9ms\n",
            "video 1/1 (frame 879/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 880/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 881/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.0ms\n",
            "video 1/1 (frame 882/2022) /content/test_yolo.mp4: 384x640 3 twigs, 12.4ms\n",
            "video 1/1 (frame 883/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.7ms\n",
            "video 1/1 (frame 884/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 885/2022) /content/test_yolo.mp4: 384x640 4 twigs, 5.9ms\n",
            "video 1/1 (frame 886/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 887/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 888/2022) /content/test_yolo.mp4: 384x640 4 twigs, 33.3ms\n",
            "video 1/1 (frame 889/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 890/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 891/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 892/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.9ms\n",
            "video 1/1 (frame 893/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.0ms\n",
            "video 1/1 (frame 894/2022) /content/test_yolo.mp4: 384x640 3 twigs, 15.4ms\n",
            "video 1/1 (frame 895/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 896/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 897/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 898/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 899/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.8ms\n",
            "video 1/1 (frame 900/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 901/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 902/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 903/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.2ms\n",
            "video 1/1 (frame 904/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 905/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.1ms\n",
            "video 1/1 (frame 906/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.1ms\n",
            "video 1/1 (frame 907/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.9ms\n",
            "video 1/1 (frame 908/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.4ms\n",
            "video 1/1 (frame 909/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 910/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 911/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.5ms\n",
            "video 1/1 (frame 912/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.3ms\n",
            "video 1/1 (frame 913/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 914/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.6ms\n",
            "video 1/1 (frame 915/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 916/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.8ms\n",
            "video 1/1 (frame 917/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 918/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.9ms\n",
            "video 1/1 (frame 919/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.0ms\n",
            "video 1/1 (frame 920/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.0ms\n",
            "video 1/1 (frame 921/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 922/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 923/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.3ms\n",
            "video 1/1 (frame 924/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.7ms\n",
            "video 1/1 (frame 925/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.2ms\n",
            "video 1/1 (frame 926/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.9ms\n",
            "video 1/1 (frame 927/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.7ms\n",
            "video 1/1 (frame 928/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 929/2022) /content/test_yolo.mp4: 384x640 5 twigs, 7.4ms\n",
            "video 1/1 (frame 930/2022) /content/test_yolo.mp4: 384x640 5 twigs, 8.9ms\n",
            "video 1/1 (frame 931/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.1ms\n",
            "video 1/1 (frame 932/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 933/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.1ms\n",
            "video 1/1 (frame 934/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.2ms\n",
            "video 1/1 (frame 935/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.1ms\n",
            "video 1/1 (frame 936/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.0ms\n",
            "video 1/1 (frame 937/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.1ms\n",
            "video 1/1 (frame 938/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.3ms\n",
            "video 1/1 (frame 939/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.2ms\n",
            "video 1/1 (frame 940/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.2ms\n",
            "video 1/1 (frame 941/2022) /content/test_yolo.mp4: 384x640 4 twigs, 5.9ms\n",
            "video 1/1 (frame 942/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 943/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.6ms\n",
            "video 1/1 (frame 944/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 945/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.2ms\n",
            "video 1/1 (frame 946/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 947/2022) /content/test_yolo.mp4: 384x640 4 twigs, 7.0ms\n",
            "video 1/1 (frame 948/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.3ms\n",
            "video 1/1 (frame 949/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.0ms\n",
            "video 1/1 (frame 950/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.1ms\n",
            "video 1/1 (frame 951/2022) /content/test_yolo.mp4: 384x640 4 twigs, 6.9ms\n",
            "video 1/1 (frame 952/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.5ms\n",
            "video 1/1 (frame 953/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.3ms\n",
            "video 1/1 (frame 954/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.5ms\n",
            "video 1/1 (frame 955/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.3ms\n",
            "video 1/1 (frame 956/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.9ms\n",
            "video 1/1 (frame 957/2022) /content/test_yolo.mp4: 384x640 4 twigs, 15.9ms\n",
            "video 1/1 (frame 958/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.7ms\n",
            "video 1/1 (frame 959/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.6ms\n",
            "video 1/1 (frame 960/2022) /content/test_yolo.mp4: 384x640 4 twigs, 14.7ms\n",
            "video 1/1 (frame 961/2022) /content/test_yolo.mp4: 384x640 4 twigs, 9.6ms\n",
            "video 1/1 (frame 962/2022) /content/test_yolo.mp4: 384x640 4 twigs, 13.8ms\n",
            "video 1/1 (frame 963/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.1ms\n",
            "video 1/1 (frame 964/2022) /content/test_yolo.mp4: 384x640 4 twigs, 12.9ms\n",
            "video 1/1 (frame 965/2022) /content/test_yolo.mp4: 384x640 4 twigs, 8.6ms\n",
            "video 1/1 (frame 966/2022) /content/test_yolo.mp4: 384x640 4 twigs, 15.8ms\n",
            "video 1/1 (frame 967/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.6ms\n",
            "video 1/1 (frame 968/2022) /content/test_yolo.mp4: 384x640 3 twigs, 13.2ms\n",
            "video 1/1 (frame 969/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.9ms\n",
            "video 1/1 (frame 970/2022) /content/test_yolo.mp4: 384x640 3 twigs, 12.4ms\n",
            "video 1/1 (frame 971/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.7ms\n",
            "video 1/1 (frame 972/2022) /content/test_yolo.mp4: 384x640 4 twigs, 11.5ms\n",
            "video 1/1 (frame 973/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.5ms\n",
            "video 1/1 (frame 974/2022) /content/test_yolo.mp4: 384x640 4 twigs, 10.7ms\n",
            "video 1/1 (frame 975/2022) /content/test_yolo.mp4: 384x640 3 twigs, 13.7ms\n",
            "video 1/1 (frame 976/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.9ms\n",
            "video 1/1 (frame 977/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.7ms\n",
            "video 1/1 (frame 978/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.0ms\n",
            "video 1/1 (frame 979/2022) /content/test_yolo.mp4: 384x640 3 twigs, 14.7ms\n",
            "video 1/1 (frame 980/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.8ms\n",
            "video 1/1 (frame 981/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.5ms\n",
            "video 1/1 (frame 982/2022) /content/test_yolo.mp4: 384x640 3 twigs, 11.6ms\n",
            "video 1/1 (frame 983/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.9ms\n",
            "video 1/1 (frame 984/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.8ms\n",
            "video 1/1 (frame 985/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.4ms\n",
            "video 1/1 (frame 986/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 987/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.8ms\n",
            "video 1/1 (frame 988/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.1ms\n",
            "video 1/1 (frame 989/2022) /content/test_yolo.mp4: 384x640 3 twigs, 608.1ms\n",
            "video 1/1 (frame 990/2022) /content/test_yolo.mp4: 384x640 3 twigs, 34.2ms\n",
            "video 1/1 (frame 991/2022) /content/test_yolo.mp4: 384x640 3 twigs, 29.0ms\n",
            "video 1/1 (frame 992/2022) /content/test_yolo.mp4: 384x640 3 twigs, 36.6ms\n",
            "video 1/1 (frame 993/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.9ms\n",
            "video 1/1 (frame 994/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 995/2022) /content/test_yolo.mp4: 384x640 3 twigs, 12.4ms\n",
            "video 1/1 (frame 996/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.6ms\n",
            "video 1/1 (frame 997/2022) /content/test_yolo.mp4: 384x640 3 twigs, 19.1ms\n",
            "video 1/1 (frame 998/2022) /content/test_yolo.mp4: 384x640 3 twigs, 20.6ms\n",
            "video 1/1 (frame 999/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.7ms\n",
            "video 1/1 (frame 1000/2022) /content/test_yolo.mp4: 384x640 3 twigs, 55017.4ms\n",
            "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
            "video 1/1 (frame 1001/2022) /content/test_yolo.mp4: 384x640 3 twigs, 78665.9ms\n",
            "video 1/1 (frame 1002/2022) /content/test_yolo.mp4: 384x640 3 twigs, 263.7ms\n",
            "video 1/1 (frame 1003/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.5ms\n",
            "video 1/1 (frame 1004/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.0ms\n",
            "video 1/1 (frame 1005/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.9ms\n",
            "video 1/1 (frame 1006/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.1ms\n",
            "video 1/1 (frame 1007/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.3ms\n",
            "video 1/1 (frame 1008/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.4ms\n",
            "video 1/1 (frame 1009/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.4ms\n",
            "video 1/1 (frame 1010/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.3ms\n",
            "video 1/1 (frame 1011/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.0ms\n",
            "video 1/1 (frame 1012/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.2ms\n",
            "video 1/1 (frame 1013/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.1ms\n",
            "video 1/1 (frame 1014/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.7ms\n",
            "video 1/1 (frame 1015/2022) /content/test_yolo.mp4: 384x640 3 twigs, 26.3ms\n",
            "video 1/1 (frame 1016/2022) /content/test_yolo.mp4: 384x640 3 twigs, 19.3ms\n",
            "video 1/1 (frame 1017/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.3ms\n",
            "video 1/1 (frame 1018/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.2ms\n",
            "video 1/1 (frame 1019/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 1020/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.2ms\n",
            "video 1/1 (frame 1021/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.1ms\n",
            "video 1/1 (frame 1022/2022) /content/test_yolo.mp4: 384x640 3 twigs, 11.9ms\n",
            "video 1/1 (frame 1023/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.3ms\n",
            "video 1/1 (frame 1024/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.7ms\n",
            "video 1/1 (frame 1025/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.3ms\n",
            "video 1/1 (frame 1026/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.8ms\n",
            "video 1/1 (frame 1027/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.5ms\n",
            "video 1/1 (frame 1028/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.9ms\n",
            "video 1/1 (frame 1029/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.4ms\n",
            "video 1/1 (frame 1030/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.0ms\n",
            "video 1/1 (frame 1031/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.5ms\n",
            "video 1/1 (frame 1032/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.6ms\n",
            "video 1/1 (frame 1033/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.7ms\n",
            "video 1/1 (frame 1034/2022) /content/test_yolo.mp4: 384x640 3 twigs, 9.1ms\n",
            "video 1/1 (frame 1035/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.6ms\n",
            "video 1/1 (frame 1036/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.5ms\n",
            "video 1/1 (frame 1037/2022) /content/test_yolo.mp4: 384x640 3 twigs, 11.5ms\n",
            "video 1/1 (frame 1038/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.4ms\n",
            "video 1/1 (frame 1039/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.7ms\n",
            "video 1/1 (frame 1040/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.3ms\n",
            "video 1/1 (frame 1041/2022) /content/test_yolo.mp4: 384x640 3 twigs, 7.4ms\n",
            "video 1/1 (frame 1042/2022) /content/test_yolo.mp4: 384x640 3 twigs, 10.0ms\n",
            "video 1/1 (frame 1043/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.3ms\n",
            "video 1/1 (frame 1044/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.6ms\n",
            "video 1/1 (frame 1045/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.6ms\n",
            "video 1/1 (frame 1046/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.3ms\n",
            "video 1/1 (frame 1047/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.3ms\n",
            "video 1/1 (frame 1048/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.5ms\n",
            "video 1/1 (frame 1049/2022) /content/test_yolo.mp4: 384x640 3 twigs, 6.7ms\n",
            "video 1/1 (frame 1050/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.7ms\n",
            "video 1/1 (frame 1051/2022) /content/test_yolo.mp4: 384x640 3 twigs, 8.1ms\n",
            "video 1/1 (frame 1052/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.6ms\n",
            "video 1/1 (frame 1053/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.4ms\n",
            "video 1/1 (frame 1054/2022) /content/test_yolo.mp4: 384x640 2 twigs, 9.7ms\n",
            "video 1/1 (frame 1055/2022) /content/test_yolo.mp4: 384x640 2 twigs, 7.7ms\n",
            "video 1/1 (frame 1056/2022) /content/test_yolo.mp4: 384x640 2 twigs, 6.1ms\n",
            "video 1/1 (frame 1057/2022) /content/test_yolo.mp4: 384x640 2 twigs, 8.3ms\n",
            "video 1/1 (frame 1058/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.2ms\n",
            "video 1/1 (frame 1059/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.8ms\n",
            "video 1/1 (frame 1060/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.9ms\n",
            "video 1/1 (frame 1061/2022) /content/test_yolo.mp4: 384x640 1 twig, 16.2ms\n",
            "video 1/1 (frame 1062/2022) /content/test_yolo.mp4: 384x640 1 twig, 9.9ms\n",
            "video 1/1 (frame 1063/2022) /content/test_yolo.mp4: 384x640 1 twig, 6.0ms\n",
            "video 1/1 (frame 1064/2022) /content/test_yolo.mp4: 384x640 1 twig, 8.2ms\n",
            "video 1/1 (frame 1065/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.8ms\n",
            "video 1/1 (frame 1066/2022) /content/test_yolo.mp4: 384x640 (no detections), 10.0ms\n",
            "video 1/1 (frame 1067/2022) /content/test_yolo.mp4: 384x640 (no detections), 8.4ms\n",
            "video 1/1 (frame 1068/2022) /content/test_yolo.mp4: 384x640 (no detections), 8.3ms\n",
            "video 1/1 (frame 1069/2022) /content/test_yolo.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (frame 1070/2022) /content/test_yolo.mp4: 384x640 (no detections), 7.6ms\n",
            "video 1/1 (frame 1071/2022) /content/test_yolo.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (frame 1072/2022) /content/test_yolo.mp4: 384x640 (no detections), 8.0ms\n",
            "video 1/1 (frame 1073/2022) /content/test_yolo.mp4: 384x640 (no detections), 6.7ms\n",
            "video 1/1 (frame 1074/2022) /content/test_yolo.mp4: 384x640 (no detections), 6.7ms\n",
            "video 1/1 (frame 1075/2022) /content/test_yolo.mp4: 384x640 (no detections), 9.2ms\n",
            "video 1/1 (frame 1076/2022) /content/test_yolo.mp4: 384x640 1 twig, 8.3ms\n",
            "video 1/1 (frame 1077/2022) /content/test_yolo.mp4: 384x640 1 twig, 8.5ms\n",
            "video 1/1 (frame 1078/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.2ms\n",
            "video 1/1 (frame 1079/2022) /content/test_yolo.mp4: 384x640 1 twig, 7.0ms\n",
            "WARNING âš ï¸ NMS time limit 2.050s exceeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "# YOLOv8 ì˜ìƒ ì²˜ë¦¬ (RAM ì ˆëŒ€ ì•ˆ í„°ì§€ëŠ” ì•ˆì „ ë²„ì „)\n",
        "###############################################\n",
        "\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# YOLO ëª¨ë¸ ë¡œë“œ\n",
        "model = YOLO(\"runs/detect/floating_matters_yolov8n_v3/weights/best.pt\")\n",
        "\n",
        "# ì…ë ¥ ì˜ìƒ\n",
        "input_video = \"/content/test_yolo.mp4\"\n",
        "\n",
        "# ë¹„ë””ì˜¤ ìº¡ì²˜ ì—´ê¸°\n",
        "cap = cv2.VideoCapture(input_video)\n",
        "\n",
        "# ë¹„ë””ì˜¤ ì •ë³´ ì½ê¸°\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# mp4ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ ì„¤ì •\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "output_path = \"/content/output_yolo.mp4\"\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "frame_idx = 0\n",
        "\n",
        "print(\"ğŸ¬ ì˜ìƒ ì²˜ë¦¬ ì‹œì‘... (RAM ì•ˆì „ëª¨ë“œ)\")\n",
        "\n",
        "# í”„ë ˆì„ ë‹¨ìœ„ ì²˜ë¦¬\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # YOLO ì¶”ë¡ \n",
        "    results = model(frame, conf=0.75, verbose=True)\n",
        "    #  confë¡œ ì •í™•ë„ 75%ì´ìƒì¸ ê°ì²´ë§Œ ì¶œë ¥, verboseë¡œ ìì„¸í•œ ë¡œê·¸ ì¶œë ¥\n",
        "\n",
        "    # YOLOê°€ ê·¸ë¦° í”„ë ˆì„ ì–»ê¸°\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # ê²°ê³¼ ì˜ìƒì— ì“°ê¸°\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    frame_idx += 1\n",
        "    if frame_idx % 50 == 0:\n",
        "        print(f\"Processed frame: {frame_idx}\")\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"ğŸ‰ ì˜ìƒ ì €ì¥ ì™„ë£Œ:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4VZSpgAQShe",
        "outputId": "9deffb36-a680-489f-fc0d-9e0a96bc4f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ë‚´ìš©ì´ ê¸¸ì–´ì„œ ë§ˆì§€ë§‰ 5000ì¤„ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\u001b[0m\n",
            "Speed: 3.5ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.5ms\n",
            "Speed: 5.8ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.1ms\n",
            "Speed: 3.2ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.5ms\n",
            "Speed: 3.0ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.7ms\n",
            "Speed: 3.5ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.3ms\n",
            "Speed: 2.1ms preprocess, 6.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.0ms\n",
            "Speed: 3.8ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.7ms\n",
            "Speed: 3.0ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.9ms\n",
            "Speed: 2.8ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.4ms\n",
            "Speed: 4.1ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.4ms\n",
            "Speed: 2.6ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 4.1ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 4.3ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 400\n",
            "\n",
            "0: 384x640 4 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 5.9ms\n",
            "Speed: 3.6ms preprocess, 5.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 3.9ms preprocess, 7.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.9ms\n",
            "Speed: 2.8ms preprocess, 6.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.1ms\n",
            "Speed: 7.5ms preprocess, 10.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.0ms\n",
            "Speed: 4.6ms preprocess, 10.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.6ms\n",
            "Speed: 5.8ms preprocess, 10.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 12.4ms\n",
            "Speed: 4.1ms preprocess, 12.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 15.9ms\n",
            "Speed: 5.6ms preprocess, 15.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 4.7ms preprocess, 7.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 14.2ms\n",
            "Speed: 7.1ms preprocess, 14.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.2ms\n",
            "Speed: 3.9ms preprocess, 8.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 18.9ms\n",
            "Speed: 12.3ms preprocess, 18.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.9ms\n",
            "Speed: 5.0ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 17.3ms\n",
            "Speed: 4.8ms preprocess, 17.3ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.0ms\n",
            "Speed: 5.1ms preprocess, 15.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.2ms\n",
            "Speed: 5.0ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.6ms\n",
            "Speed: 6.9ms preprocess, 13.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.3ms\n",
            "Speed: 6.6ms preprocess, 11.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.3ms\n",
            "Speed: 5.7ms preprocess, 13.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 16.4ms\n",
            "Speed: 5.2ms preprocess, 16.4ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 12.5ms\n",
            "Speed: 4.0ms preprocess, 12.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.4ms\n",
            "Speed: 5.9ms preprocess, 15.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.2ms\n",
            "Speed: 4.1ms preprocess, 7.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.8ms\n",
            "Speed: 6.5ms preprocess, 15.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.9ms\n",
            "Speed: 4.8ms preprocess, 7.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 20.1ms\n",
            "Speed: 5.9ms preprocess, 20.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.7ms\n",
            "Speed: 4.9ms preprocess, 14.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.9ms\n",
            "Speed: 4.8ms preprocess, 8.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.1ms\n",
            "Speed: 6.0ms preprocess, 14.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.9ms\n",
            "Speed: 5.6ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 4.5ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 14.1ms\n",
            "Speed: 6.2ms preprocess, 14.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 14.4ms\n",
            "Speed: 4.6ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 16.9ms\n",
            "Speed: 4.7ms preprocess, 16.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 450\n",
            "\n",
            "0: 384x640 3 twigs, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.0ms\n",
            "Speed: 4.7ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.7ms\n",
            "Speed: 5.8ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 14.3ms\n",
            "Speed: 6.9ms preprocess, 14.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.7ms\n",
            "Speed: 5.5ms preprocess, 11.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 13.2ms\n",
            "Speed: 4.3ms preprocess, 13.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.8ms\n",
            "Speed: 4.4ms preprocess, 11.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 16.1ms\n",
            "Speed: 4.7ms preprocess, 16.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.0ms\n",
            "Speed: 4.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 6.7ms preprocess, 8.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.5ms\n",
            "Speed: 4.5ms preprocess, 10.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 18.4ms\n",
            "Speed: 6.4ms preprocess, 18.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 17.0ms\n",
            "Speed: 4.9ms preprocess, 17.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 13.1ms\n",
            "Speed: 3.4ms preprocess, 13.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.1ms\n",
            "Speed: 5.5ms preprocess, 13.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.3ms\n",
            "Speed: 3.0ms preprocess, 14.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 12.6ms\n",
            "Speed: 5.1ms preprocess, 12.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.8ms\n",
            "Speed: 4.8ms preprocess, 13.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.3ms\n",
            "Speed: 7.7ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.0ms\n",
            "Speed: 3.8ms preprocess, 6.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.4ms\n",
            "Speed: 4.0ms preprocess, 6.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.3ms\n",
            "Speed: 4.8ms preprocess, 9.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.0ms\n",
            "Speed: 3.9ms preprocess, 7.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.3ms\n",
            "Speed: 2.0ms preprocess, 6.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.4ms\n",
            "Speed: 4.8ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.0ms\n",
            "Speed: 2.3ms preprocess, 6.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.7ms\n",
            "Speed: 3.4ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.9ms\n",
            "Speed: 2.8ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 3.3ms preprocess, 8.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.4ms\n",
            "Speed: 2.4ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.0ms\n",
            "Speed: 2.9ms preprocess, 6.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.1ms\n",
            "Speed: 3.2ms preprocess, 6.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 500\n",
            "\n",
            "0: 384x640 3 twigs, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 5.6ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.4ms\n",
            "Speed: 2.9ms preprocess, 6.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.9ms\n",
            "Speed: 2.9ms preprocess, 6.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 4.9ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.3ms\n",
            "Speed: 2.9ms preprocess, 7.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.5ms\n",
            "Speed: 4.2ms preprocess, 7.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.2ms\n",
            "Speed: 3.7ms preprocess, 6.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.4ms\n",
            "Speed: 4.1ms preprocess, 8.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.0ms\n",
            "Speed: 4.5ms preprocess, 6.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.3ms\n",
            "Speed: 5.6ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 5.9ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 3.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 16.1ms\n",
            "Speed: 5.1ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.0ms\n",
            "Speed: 3.9ms preprocess, 6.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 4.5ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 3.8ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 3.8ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.3ms\n",
            "Speed: 3.0ms preprocess, 6.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.5ms\n",
            "Speed: 6.2ms preprocess, 8.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.1ms\n",
            "Speed: 3.0ms preprocess, 6.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 5.0ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 5.0ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.9ms\n",
            "Speed: 2.8ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 3.7ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 3.5ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 550\n",
            "\n",
            "0: 384x640 3 twigs, 6.0ms\n",
            "Speed: 4.7ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.4ms\n",
            "Speed: 4.9ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.1ms\n",
            "Speed: 3.6ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 5.3ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.5ms\n",
            "Speed: 4.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.4ms\n",
            "Speed: 5.1ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.0ms\n",
            "Speed: 4.9ms preprocess, 8.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 2.8ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.3ms\n",
            "Speed: 4.7ms preprocess, 6.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.4ms\n",
            "Speed: 2.0ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.2ms\n",
            "Speed: 4.0ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.4ms\n",
            "Speed: 4.0ms preprocess, 6.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.4ms\n",
            "Speed: 3.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 6.0ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.2ms\n",
            "Speed: 5.6ms preprocess, 9.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 600\n",
            "\n",
            "0: 384x640 3 twigs, 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.1ms\n",
            "Speed: 5.7ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.5ms\n",
            "Speed: 3.2ms preprocess, 15.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 6.9ms\n",
            "Speed: 5.3ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.5ms\n",
            "Speed: 3.6ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.8ms\n",
            "Speed: 3.4ms preprocess, 6.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 4.7ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.6ms\n",
            "Speed: 4.7ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 6.5ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.1ms\n",
            "Speed: 4.6ms preprocess, 8.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.8ms\n",
            "Speed: 4.5ms preprocess, 7.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.0ms\n",
            "Speed: 3.7ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.6ms\n",
            "Speed: 5.7ms preprocess, 11.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.0ms\n",
            "Speed: 5.1ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.9ms\n",
            "Speed: 4.7ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.3ms\n",
            "Speed: 3.3ms preprocess, 14.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.7ms\n",
            "Speed: 3.8ms preprocess, 6.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.0ms\n",
            "Speed: 3.8ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.3ms\n",
            "Speed: 2.9ms preprocess, 7.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.1ms\n",
            "Speed: 4.4ms preprocess, 6.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 650\n",
            "\n",
            "0: 384x640 3 twigs, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.5ms\n",
            "Speed: 2.7ms preprocess, 6.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.4ms\n",
            "Speed: 5.2ms preprocess, 15.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 3.7ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.4ms\n",
            "Speed: 4.0ms preprocess, 9.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.4ms\n",
            "Speed: 5.0ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.4ms\n",
            "Speed: 4.3ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.9ms\n",
            "Speed: 4.6ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.1ms\n",
            "Speed: 4.0ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 4.2ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.7ms\n",
            "Speed: 3.6ms preprocess, 6.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.3ms\n",
            "Speed: 5.6ms preprocess, 9.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 6.7ms\n",
            "Speed: 3.1ms preprocess, 6.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 6.1ms\n",
            "Speed: 4.4ms preprocess, 6.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.7ms\n",
            "Speed: 3.7ms preprocess, 9.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 700\n",
            "\n",
            "0: 384x640 5 twigs, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.9ms\n",
            "Speed: 3.1ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.3ms\n",
            "Speed: 3.6ms preprocess, 9.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.7ms\n",
            "Speed: 5.3ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.3ms\n",
            "Speed: 4.0ms preprocess, 7.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.1ms\n",
            "Speed: 3.4ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.1ms\n",
            "Speed: 4.2ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.0ms\n",
            "Speed: 4.1ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.3ms\n",
            "Speed: 3.5ms preprocess, 6.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.0ms\n",
            "Speed: 4.9ms preprocess, 7.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.4ms\n",
            "Speed: 4.1ms preprocess, 11.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.9ms\n",
            "Speed: 4.3ms preprocess, 6.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.9ms\n",
            "Speed: 4.0ms preprocess, 11.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.1ms\n",
            "Speed: 7.7ms preprocess, 14.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 14.8ms\n",
            "Speed: 4.6ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 19.0ms\n",
            "Speed: 9.4ms preprocess, 19.0ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.4ms\n",
            "Speed: 5.1ms preprocess, 14.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 5.7ms preprocess, 9.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 18.7ms\n",
            "Speed: 7.0ms preprocess, 18.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.9ms\n",
            "Speed: 4.4ms preprocess, 11.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.1ms\n",
            "Speed: 7.2ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.3ms\n",
            "Speed: 4.4ms preprocess, 13.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.9ms\n",
            "Speed: 5.0ms preprocess, 13.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.1ms\n",
            "Speed: 6.4ms preprocess, 15.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.6ms\n",
            "Speed: 4.1ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.9ms\n",
            "Speed: 4.6ms preprocess, 10.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.1ms\n",
            "Speed: 4.6ms preprocess, 13.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 25.0ms\n",
            "Speed: 7.3ms preprocess, 25.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 750\n",
            "\n",
            "0: 384x640 3 twigs, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 17.4ms\n",
            "Speed: 7.2ms preprocess, 17.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 16.4ms\n",
            "Speed: 5.1ms preprocess, 16.4ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.7ms\n",
            "Speed: 3.9ms preprocess, 8.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.1ms\n",
            "Speed: 3.9ms preprocess, 11.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.4ms\n",
            "Speed: 4.9ms preprocess, 10.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.3ms\n",
            "Speed: 4.1ms preprocess, 13.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 17.1ms\n",
            "Speed: 4.4ms preprocess, 17.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.4ms\n",
            "Speed: 5.0ms preprocess, 9.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 10.2ms\n",
            "Speed: 3.8ms preprocess, 10.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 10.0ms\n",
            "Speed: 4.5ms preprocess, 10.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.4ms\n",
            "Speed: 4.8ms preprocess, 9.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 13.0ms\n",
            "Speed: 4.9ms preprocess, 13.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 10.6ms\n",
            "Speed: 4.3ms preprocess, 10.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 10.6ms\n",
            "Speed: 5.1ms preprocess, 10.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.7ms\n",
            "Speed: 5.0ms preprocess, 9.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 11.1ms\n",
            "Speed: 4.1ms preprocess, 11.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.8ms\n",
            "Speed: 4.9ms preprocess, 9.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 12.9ms\n",
            "Speed: 7.1ms preprocess, 12.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 21.5ms\n",
            "Speed: 7.0ms preprocess, 21.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 10.6ms\n",
            "Speed: 4.7ms preprocess, 10.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 21.2ms\n",
            "Speed: 4.9ms preprocess, 21.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 13.6ms\n",
            "Speed: 5.2ms preprocess, 13.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 7.5ms\n",
            "Speed: 4.8ms preprocess, 7.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 twigs, 15.1ms\n",
            "Speed: 5.1ms preprocess, 15.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.8ms\n",
            "Speed: 5.0ms preprocess, 15.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.9ms\n",
            "Speed: 4.3ms preprocess, 15.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.6ms\n",
            "Speed: 5.8ms preprocess, 13.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 17.6ms\n",
            "Speed: 5.7ms preprocess, 17.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.9ms\n",
            "Speed: 5.3ms preprocess, 13.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 13.6ms\n",
            "Speed: 4.2ms preprocess, 13.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 15.1ms\n",
            "Speed: 7.0ms preprocess, 15.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 14.5ms\n",
            "Speed: 3.9ms preprocess, 14.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 3.9ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 800\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 2.8ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 4.0ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 16.1ms\n",
            "Speed: 2.0ms preprocess, 16.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 5.2ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.6ms\n",
            "Speed: 3.3ms preprocess, 7.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.4ms\n",
            "Speed: 5.7ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.4ms\n",
            "Speed: 4.8ms preprocess, 9.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.5ms\n",
            "Speed: 4.3ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.2ms\n",
            "Speed: 2.5ms preprocess, 6.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.3ms\n",
            "Speed: 5.5ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 4.6ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.0ms\n",
            "Speed: 4.1ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.5ms\n",
            "Speed: 6.0ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.3ms\n",
            "Speed: 3.1ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.0ms\n",
            "Speed: 3.1ms preprocess, 6.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 3.9ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.1ms\n",
            "Speed: 4.4ms preprocess, 6.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 4.0ms preprocess, 9.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 850\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.2ms\n",
            "Speed: 3.9ms preprocess, 9.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.5ms\n",
            "Speed: 3.9ms preprocess, 7.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.2ms\n",
            "Speed: 3.8ms preprocess, 6.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.2ms\n",
            "Speed: 3.8ms preprocess, 6.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.2ms\n",
            "Speed: 4.0ms preprocess, 9.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.5ms\n",
            "Speed: 5.1ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.3ms\n",
            "Speed: 2.9ms preprocess, 7.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.8ms\n",
            "Speed: 5.4ms preprocess, 8.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.6ms\n",
            "Speed: 4.6ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 3.3ms preprocess, 7.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.9ms\n",
            "Speed: 4.9ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.1ms\n",
            "Speed: 5.3ms preprocess, 9.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.8ms\n",
            "Speed: 3.6ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.9ms\n",
            "Speed: 5.0ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.7ms\n",
            "Speed: 3.2ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.7ms\n",
            "Speed: 5.3ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.2ms\n",
            "Speed: 3.1ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 900\n",
            "\n",
            "0: 384x640 2 twigs, 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 3.8ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.7ms\n",
            "Speed: 5.5ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.1ms\n",
            "Speed: 3.9ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.9ms\n",
            "Speed: 4.9ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 3.9ms preprocess, 7.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.7ms\n",
            "Speed: 3.7ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.7ms\n",
            "Speed: 3.8ms preprocess, 8.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.9ms\n",
            "Speed: 4.2ms preprocess, 10.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 4.2ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.8ms\n",
            "Speed: 3.0ms preprocess, 6.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 4.2ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.2ms\n",
            "Speed: 4.0ms preprocess, 10.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.0ms\n",
            "Speed: 4.8ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.0ms\n",
            "Speed: 4.7ms preprocess, 6.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 6.9ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.7ms\n",
            "Speed: 2.8ms preprocess, 6.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 7.0ms\n",
            "Speed: 2.9ms preprocess, 7.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 6.8ms\n",
            "Speed: 4.2ms preprocess, 6.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.4ms\n",
            "Speed: 4.5ms preprocess, 10.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.9ms\n",
            "Speed: 3.2ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.9ms\n",
            "Speed: 4.6ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 9.2ms\n",
            "Speed: 3.8ms preprocess, 9.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 950\n",
            "\n",
            "0: 384x640 4 twigs, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 twigs, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.8ms\n",
            "Speed: 3.8ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.1ms\n",
            "Speed: 3.1ms preprocess, 6.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.4ms\n",
            "Speed: 3.6ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.7ms\n",
            "Speed: 5.4ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.7ms\n",
            "Speed: 3.2ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.4ms\n",
            "Speed: 4.2ms preprocess, 6.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 11.0ms\n",
            "Speed: 2.9ms preprocess, 11.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.9ms\n",
            "Speed: 6.1ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.7ms\n",
            "Speed: 4.9ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.3ms\n",
            "Speed: 3.0ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.3ms\n",
            "Speed: 4.7ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.2ms\n",
            "Speed: 3.3ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.5ms\n",
            "Speed: 2.8ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 5.0ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.9ms\n",
            "Speed: 3.2ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.4ms\n",
            "Speed: 3.7ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 15.7ms\n",
            "Speed: 3.8ms preprocess, 15.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 6.9ms\n",
            "Speed: 3.9ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1000\n",
            "\n",
            "0: 384x640 2 twigs, 6.1ms\n",
            "Speed: 4.2ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.0ms\n",
            "Speed: 4.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.4ms\n",
            "Speed: 4.2ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 6.0ms\n",
            "Speed: 2.9ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.5ms\n",
            "Speed: 6.1ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.0ms\n",
            "Speed: 4.6ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.4ms\n",
            "Speed: 3.7ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.1ms\n",
            "Speed: 4.8ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.3ms\n",
            "Speed: 3.1ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.2ms\n",
            "Speed: 4.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 12.2ms\n",
            "Speed: 3.0ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 4.6ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.6ms\n",
            "Speed: 3.6ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.8ms\n",
            "Speed: 3.3ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.3ms\n",
            "Speed: 4.5ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.5ms\n",
            "Speed: 3.9ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.0ms\n",
            "Speed: 3.8ms preprocess, 6.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 7.8ms\n",
            "Speed: 3.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1050\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 3.1ms preprocess, 13.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 7.0ms preprocess, 9.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.1ms\n",
            "Speed: 6.3ms preprocess, 16.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.9ms\n",
            "Speed: 5.1ms preprocess, 12.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 4.2ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 4.6ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 4.1ms preprocess, 14.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 4.5ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 14.2ms\n",
            "Speed: 5.6ms preprocess, 14.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 17.3ms\n",
            "Speed: 5.2ms preprocess, 17.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 16.7ms\n",
            "Speed: 3.0ms preprocess, 16.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 15.3ms\n",
            "Speed: 6.3ms preprocess, 15.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 5.9ms preprocess, 11.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 12.6ms\n",
            "Speed: 3.8ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.0ms\n",
            "Speed: 8.5ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.4ms\n",
            "Speed: 4.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 15.2ms\n",
            "Speed: 4.2ms preprocess, 15.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 12.3ms\n",
            "Speed: 4.2ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1100\n",
            "\n",
            "0: 384x640 1 twig, 9.3ms\n",
            "Speed: 4.2ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.4ms\n",
            "Speed: 3.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 12.2ms\n",
            "Speed: 5.7ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 11.5ms\n",
            "Speed: 4.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 14.0ms\n",
            "Speed: 5.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.5ms\n",
            "Speed: 6.8ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 11.5ms\n",
            "Speed: 7.3ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.3ms\n",
            "Speed: 10.3ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.7ms\n",
            "Speed: 4.2ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 14.5ms\n",
            "Speed: 3.6ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.2ms\n",
            "Speed: 3.4ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.8ms\n",
            "Speed: 3.9ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.5ms\n",
            "Speed: 4.0ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 14.7ms\n",
            "Speed: 4.0ms preprocess, 14.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 13.2ms\n",
            "Speed: 3.2ms preprocess, 13.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 13.5ms\n",
            "Speed: 3.1ms preprocess, 13.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.5ms\n",
            "Speed: 5.4ms preprocess, 10.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 20.5ms\n",
            "Speed: 7.2ms preprocess, 20.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 14.8ms\n",
            "Speed: 3.7ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 17.6ms\n",
            "Speed: 3.7ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 16.4ms\n",
            "Speed: 6.0ms preprocess, 16.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 18.4ms\n",
            "Speed: 4.4ms preprocess, 18.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 15.5ms\n",
            "Speed: 6.4ms preprocess, 15.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 16.2ms\n",
            "Speed: 7.7ms preprocess, 16.2ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 13.3ms\n",
            "Speed: 10.9ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 14.9ms\n",
            "Speed: 6.6ms preprocess, 14.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 13.5ms\n",
            "Speed: 5.3ms preprocess, 13.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.7ms\n",
            "Speed: 2.9ms preprocess, 12.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 17.2ms\n",
            "Speed: 6.1ms preprocess, 17.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1150\n",
            "\n",
            "0: 384x640 2 twigs, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.0ms\n",
            "Speed: 3.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.0ms\n",
            "Speed: 5.6ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.1ms\n",
            "Speed: 2.9ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 3.7ms preprocess, 8.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.5ms\n",
            "Speed: 3.9ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.5ms\n",
            "Speed: 6.0ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.3ms\n",
            "Speed: 2.9ms preprocess, 6.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.2ms\n",
            "Speed: 4.8ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.2ms\n",
            "Speed: 7.3ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 6.7ms\n",
            "Speed: 3.5ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 6.6ms\n",
            "Speed: 6.0ms preprocess, 6.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 8.4ms\n",
            "Speed: 4.3ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 4 twigs, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 4 twigs, 8.8ms\n",
            "Speed: 3.7ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.0ms\n",
            "Speed: 4.8ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 7.1ms\n",
            "Speed: 5.0ms preprocess, 7.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 7.4ms\n",
            "Speed: 3.0ms preprocess, 7.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.4ms\n",
            "Speed: 5.4ms preprocess, 8.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 6.4ms\n",
            "Speed: 3.2ms preprocess, 6.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.4ms\n",
            "Speed: 3.9ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 10.0ms\n",
            "Speed: 4.7ms preprocess, 10.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.1ms\n",
            "Speed: 2.9ms preprocess, 7.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.9ms\n",
            "Speed: 5.7ms preprocess, 9.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1200\n",
            "\n",
            "0: 384x640 2 plastics, 4 twigs, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.1ms\n",
            "Speed: 3.6ms preprocess, 8.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 14.3ms\n",
            "Speed: 2.9ms preprocess, 14.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.5ms\n",
            "Speed: 3.9ms preprocess, 7.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.9ms\n",
            "Speed: 5.5ms preprocess, 8.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.1ms\n",
            "Speed: 5.0ms preprocess, 9.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.0ms\n",
            "Speed: 5.8ms preprocess, 9.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 8.3ms\n",
            "Speed: 5.1ms preprocess, 8.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 3 twigs, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 3 twigs, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 3 twigs, 8.7ms\n",
            "Speed: 4.1ms preprocess, 8.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 3 twigs, 8.0ms\n",
            "Speed: 4.9ms preprocess, 8.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 7.7ms\n",
            "Speed: 5.0ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 6.9ms\n",
            "Speed: 3.0ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 9.8ms\n",
            "Speed: 4.3ms preprocess, 9.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 7.2ms\n",
            "Speed: 2.8ms preprocess, 7.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 6.9ms\n",
            "Speed: 4.7ms preprocess, 6.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1250\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 7.3ms\n",
            "Speed: 3.4ms preprocess, 7.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 1 twig, 11.3ms\n",
            "Speed: 7.0ms preprocess, 11.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 1 twig, 9.2ms\n",
            "Speed: 4.0ms preprocess, 9.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 1 twig, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 1 twig, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.1ms\n",
            "Speed: 3.9ms preprocess, 9.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 12.0ms\n",
            "Speed: 3.6ms preprocess, 12.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 9.5ms\n",
            "Speed: 4.0ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 6.9ms\n",
            "Speed: 5.8ms preprocess, 6.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 6.1ms\n",
            "Speed: 4.8ms preprocess, 6.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 8.4ms\n",
            "Speed: 4.5ms preprocess, 8.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 2 twigs, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 2 twigs, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.0ms\n",
            "Speed: 9.4ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 2 twigs, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 2 twigs, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 2 twigs, 7.4ms\n",
            "Speed: 6.6ms preprocess, 7.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 8.0ms\n",
            "Speed: 3.3ms preprocess, 8.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 10.2ms\n",
            "Speed: 4.7ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 7.6ms\n",
            "Speed: 3.9ms preprocess, 7.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 8.1ms\n",
            "Speed: 2.8ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1300\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.9ms\n",
            "Speed: 4.7ms preprocess, 9.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 6.9ms\n",
            "Speed: 3.1ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.7ms\n",
            "Speed: 5.8ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 6.5ms\n",
            "Speed: 6.1ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 14.1ms\n",
            "Speed: 4.9ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.0ms\n",
            "Speed: 4.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.5ms\n",
            "Speed: 4.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.4ms\n",
            "Speed: 5.1ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 6.8ms\n",
            "Speed: 3.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.1ms\n",
            "Speed: 4.1ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.3ms\n",
            "Speed: 3.9ms preprocess, 9.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.2ms\n",
            "Speed: 3.8ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 6.5ms\n",
            "Speed: 6.6ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.0ms\n",
            "Speed: 4.8ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 9.3ms\n",
            "Speed: 5.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 9.1ms\n",
            "Speed: 3.8ms preprocess, 9.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 6.6ms\n",
            "Speed: 4.6ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.0ms\n",
            "Speed: 6.1ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 9.8ms\n",
            "Speed: 5.7ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.0ms\n",
            "Speed: 4.5ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1350\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 9.8ms\n",
            "Speed: 7.5ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 9.9ms\n",
            "Speed: 3.7ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.0ms\n",
            "Speed: 4.9ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.5ms\n",
            "Speed: 5.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.0ms\n",
            "Speed: 4.4ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 12.1ms\n",
            "Speed: 5.9ms preprocess, 12.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 6.3ms\n",
            "Speed: 4.4ms preprocess, 6.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 10.3ms\n",
            "Speed: 4.4ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 twigs, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 8.1ms\n",
            "Speed: 4.6ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 twigs, 9.3ms\n",
            "Speed: 3.9ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 twig, 10.3ms\n",
            "Speed: 4.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.2ms\n",
            "Speed: 2.9ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.9ms\n",
            "Speed: 4.5ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.0ms\n",
            "Speed: 5.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.0ms\n",
            "Speed: 5.8ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 2 twigs, 19.3ms\n",
            "Speed: 5.7ms preprocess, 19.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 11.8ms\n",
            "Speed: 6.2ms preprocess, 11.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 16.8ms\n",
            "Speed: 4.1ms preprocess, 16.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 14.4ms\n",
            "Speed: 7.5ms preprocess, 14.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 11.8ms\n",
            "Speed: 4.6ms preprocess, 11.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 11.3ms\n",
            "Speed: 4.9ms preprocess, 11.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.8ms\n",
            "Speed: 6.9ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 11.7ms\n",
            "Speed: 6.1ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 10.1ms\n",
            "Speed: 6.6ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 11.2ms\n",
            "Speed: 4.9ms preprocess, 11.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.9ms\n",
            "Speed: 4.2ms preprocess, 9.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1400\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 11.0ms\n",
            "Speed: 5.4ms preprocess, 11.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.0ms\n",
            "Speed: 5.0ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.8ms\n",
            "Speed: 3.7ms preprocess, 8.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 13.9ms\n",
            "Speed: 4.9ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 13.5ms\n",
            "Speed: 5.1ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.5ms\n",
            "Speed: 5.1ms preprocess, 10.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 19.7ms\n",
            "Speed: 5.4ms preprocess, 19.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.6ms\n",
            "Speed: 4.8ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.0ms\n",
            "Speed: 5.4ms preprocess, 8.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.9ms\n",
            "Speed: 4.8ms preprocess, 9.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.8ms\n",
            "Speed: 4.9ms preprocess, 8.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 13.5ms\n",
            "Speed: 4.9ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 12.6ms\n",
            "Speed: 4.5ms preprocess, 12.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.2ms\n",
            "Speed: 6.6ms preprocess, 11.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.1ms\n",
            "Speed: 9.9ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 16.2ms\n",
            "Speed: 3.8ms preprocess, 16.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 17.2ms\n",
            "Speed: 4.3ms preprocess, 17.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.7ms\n",
            "Speed: 3.1ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 12.1ms\n",
            "Speed: 5.2ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.1ms\n",
            "Speed: 4.3ms preprocess, 8.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 16.8ms\n",
            "Speed: 3.9ms preprocess, 16.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 11.2ms\n",
            "Speed: 5.9ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 17.8ms\n",
            "Speed: 5.0ms preprocess, 17.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 13.8ms\n",
            "Speed: 4.9ms preprocess, 13.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.9ms\n",
            "Speed: 4.9ms preprocess, 10.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 12.5ms\n",
            "Speed: 3.0ms preprocess, 12.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 8.3ms\n",
            "Speed: 7.5ms preprocess, 8.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 13.3ms\n",
            "Speed: 5.3ms preprocess, 13.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 18.7ms\n",
            "Speed: 5.9ms preprocess, 18.7ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 14.1ms\n",
            "Speed: 5.0ms preprocess, 14.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 10.5ms\n",
            "Speed: 4.7ms preprocess, 10.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 14.1ms\n",
            "Speed: 5.1ms preprocess, 14.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 12.8ms\n",
            "Speed: 4.8ms preprocess, 12.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 18.9ms\n",
            "Speed: 7.3ms preprocess, 18.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1450\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 21.1ms\n",
            "Speed: 5.1ms preprocess, 21.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 8.8ms\n",
            "Speed: 3.7ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 12.5ms\n",
            "Speed: 5.1ms preprocess, 12.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 9.5ms\n",
            "Speed: 3.8ms preprocess, 9.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 8.4ms\n",
            "Speed: 7.8ms preprocess, 8.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 14.2ms\n",
            "Speed: 5.0ms preprocess, 14.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 16.2ms\n",
            "Speed: 5.7ms preprocess, 16.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 11.5ms\n",
            "Speed: 5.5ms preprocess, 11.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 2 twigs, 14.9ms\n",
            "Speed: 5.0ms preprocess, 14.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 13.1ms\n",
            "Speed: 5.0ms preprocess, 13.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 2 twigs, 12.4ms\n",
            "Speed: 4.0ms preprocess, 12.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 12.8ms\n",
            "Speed: 4.8ms preprocess, 12.8ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 2 twigs, 11.8ms\n",
            "Speed: 9.1ms preprocess, 11.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 12.7ms\n",
            "Speed: 3.4ms preprocess, 12.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 13.3ms\n",
            "Speed: 3.9ms preprocess, 13.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 15.5ms\n",
            "Speed: 6.0ms preprocess, 15.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 26.3ms\n",
            "Speed: 4.4ms preprocess, 26.3ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 13.7ms\n",
            "Speed: 6.8ms preprocess, 13.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 16.1ms\n",
            "Speed: 8.8ms preprocess, 16.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 15.1ms\n",
            "Speed: 3.1ms preprocess, 15.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 16.8ms\n",
            "Speed: 8.2ms preprocess, 16.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 14.1ms\n",
            "Speed: 2.9ms preprocess, 14.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 19.4ms\n",
            "Speed: 6.2ms preprocess, 19.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 1 twig, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 6.6ms\n",
            "Speed: 5.4ms preprocess, 6.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 7.5ms\n",
            "Speed: 6.0ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.5ms\n",
            "Speed: 4.3ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.4ms\n",
            "Speed: 4.3ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 13.5ms\n",
            "Speed: 4.0ms preprocess, 13.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 11.1ms\n",
            "Speed: 4.7ms preprocess, 11.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 12.8ms\n",
            "Speed: 3.1ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 7.4ms\n",
            "Speed: 2.7ms preprocess, 7.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1500\n",
            "\n",
            "0: 384x640 1 plastic, 9.6ms\n",
            "Speed: 5.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 9.1ms\n",
            "Speed: 4.2ms preprocess, 9.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.2ms\n",
            "Speed: 5.5ms preprocess, 7.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 6.0ms\n",
            "Speed: 2.8ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.3ms\n",
            "Speed: 5.2ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.8ms\n",
            "Speed: 3.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 4.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.9ms\n",
            "Speed: 3.6ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.2ms\n",
            "Speed: 2.9ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.9ms\n",
            "Speed: 4.0ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 7.7ms\n",
            "Speed: 4.4ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 1 twig, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 14.1ms\n",
            "Speed: 6.0ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 8.2ms\n",
            "Speed: 3.7ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 1 twig, 9.4ms\n",
            "Speed: 3.8ms preprocess, 9.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.0ms\n",
            "Speed: 4.0ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.2ms\n",
            "Speed: 3.5ms preprocess, 8.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1550\n",
            "\n",
            "0: 384x640 4 plastics, 11.4ms\n",
            "Speed: 4.0ms preprocess, 11.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.2ms\n",
            "Speed: 4.6ms preprocess, 7.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.7ms\n",
            "Speed: 4.8ms preprocess, 7.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.1ms\n",
            "Speed: 3.7ms preprocess, 7.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.9ms\n",
            "Speed: 4.1ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.2ms\n",
            "Speed: 3.0ms preprocess, 7.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.2ms\n",
            "Speed: 3.8ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 11.1ms\n",
            "Speed: 3.9ms preprocess, 11.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 6.9ms\n",
            "Speed: 3.0ms preprocess, 6.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.5ms\n",
            "Speed: 5.0ms preprocess, 8.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 6.3ms\n",
            "Speed: 3.9ms preprocess, 6.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.1ms\n",
            "Speed: 6.0ms preprocess, 8.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.8ms\n",
            "Speed: 6.1ms preprocess, 7.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 6.3ms\n",
            "Speed: 4.4ms preprocess, 6.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.3ms\n",
            "Speed: 4.4ms preprocess, 10.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1600\n",
            "\n",
            "0: 384x640 6 plastics, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.4ms\n",
            "Speed: 4.1ms preprocess, 7.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.1ms\n",
            "Speed: 4.2ms preprocess, 9.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.5ms\n",
            "Speed: 4.8ms preprocess, 8.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.2ms\n",
            "Speed: 3.3ms preprocess, 8.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.7ms\n",
            "Speed: 3.5ms preprocess, 7.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.3ms\n",
            "Speed: 5.1ms preprocess, 10.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.5ms\n",
            "Speed: 2.8ms preprocess, 7.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.2ms\n",
            "Speed: 4.5ms preprocess, 8.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.5ms\n",
            "Speed: 5.1ms preprocess, 8.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.9ms\n",
            "Speed: 3.5ms preprocess, 7.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.7ms\n",
            "Speed: 4.9ms preprocess, 8.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.6ms\n",
            "Speed: 3.3ms preprocess, 7.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.9ms\n",
            "Speed: 5.1ms preprocess, 7.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 7.8ms\n",
            "Speed: 3.9ms preprocess, 7.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 7.8ms\n",
            "Speed: 3.8ms preprocess, 7.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 13.4ms\n",
            "Speed: 5.0ms preprocess, 13.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 6.2ms\n",
            "Speed: 5.0ms preprocess, 6.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 8.5ms\n",
            "Speed: 2.8ms preprocess, 8.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 9.0ms\n",
            "Speed: 3.7ms preprocess, 9.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.9ms\n",
            "Speed: 5.2ms preprocess, 9.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1650\n",
            "\n",
            "0: 384x640 7 plastics, 9.0ms\n",
            "Speed: 5.1ms preprocess, 9.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 7.1ms\n",
            "Speed: 3.7ms preprocess, 7.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 10.8ms\n",
            "Speed: 3.9ms preprocess, 10.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 7.8ms\n",
            "Speed: 4.0ms preprocess, 7.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.5ms\n",
            "Speed: 4.9ms preprocess, 9.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 plastics, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 plastics, 14.2ms\n",
            "Speed: 4.2ms preprocess, 14.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 11.5ms\n",
            "Speed: 4.5ms preprocess, 11.5ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 plastics, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 plastics, 9.0ms\n",
            "Speed: 2.8ms preprocess, 9.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 plastics, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 plastics, 8.8ms\n",
            "Speed: 3.7ms preprocess, 8.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 10.0ms\n",
            "Speed: 4.2ms preprocess, 10.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 plastics, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.2ms\n",
            "Speed: 4.2ms preprocess, 9.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.3ms\n",
            "Speed: 5.3ms preprocess, 11.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.3ms\n",
            "Speed: 4.4ms preprocess, 9.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 8.1ms\n",
            "Speed: 2.8ms preprocess, 8.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 11.1ms\n",
            "Speed: 5.0ms preprocess, 11.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.2ms\n",
            "Speed: 3.6ms preprocess, 9.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 7.8ms\n",
            "Speed: 5.0ms preprocess, 7.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.5ms\n",
            "Speed: 5.1ms preprocess, 8.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1700\n",
            "\n",
            "0: 384x640 6 plastics, 9.0ms\n",
            "Speed: 4.9ms preprocess, 9.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 6.1ms\n",
            "Speed: 5.5ms preprocess, 6.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 7.4ms\n",
            "Speed: 6.6ms preprocess, 7.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 14.7ms\n",
            "Speed: 4.5ms preprocess, 14.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 11.3ms\n",
            "Speed: 6.0ms preprocess, 11.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 12.5ms\n",
            "Speed: 5.6ms preprocess, 12.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 13.8ms\n",
            "Speed: 4.5ms preprocess, 13.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 14.0ms\n",
            "Speed: 4.0ms preprocess, 14.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.5ms\n",
            "Speed: 4.0ms preprocess, 10.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.5ms\n",
            "Speed: 5.4ms preprocess, 10.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.8ms\n",
            "Speed: 6.7ms preprocess, 8.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 11.1ms\n",
            "Speed: 5.1ms preprocess, 11.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.2ms\n",
            "Speed: 3.9ms preprocess, 9.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 12.2ms\n",
            "Speed: 5.0ms preprocess, 12.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.8ms\n",
            "Speed: 3.9ms preprocess, 8.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.0ms\n",
            "Speed: 5.2ms preprocess, 9.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.7ms\n",
            "Speed: 5.0ms preprocess, 9.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.7ms\n",
            "Speed: 5.0ms preprocess, 9.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 16.9ms\n",
            "Speed: 4.9ms preprocess, 16.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.6ms\n",
            "Speed: 6.3ms preprocess, 10.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 14.7ms\n",
            "Speed: 6.2ms preprocess, 14.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 18.0ms\n",
            "Speed: 3.7ms preprocess, 18.0ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 14.4ms\n",
            "Speed: 6.0ms preprocess, 14.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 plastics, 16.2ms\n",
            "Speed: 6.0ms preprocess, 16.2ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1750\n",
            "\n",
            "0: 384x640 4 plastics, 14.7ms\n",
            "Speed: 3.7ms preprocess, 14.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.0ms\n",
            "Speed: 5.6ms preprocess, 10.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.4ms\n",
            "Speed: 6.4ms preprocess, 11.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.6ms\n",
            "Speed: 2.9ms preprocess, 8.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.2ms\n",
            "Speed: 4.9ms preprocess, 10.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.5ms\n",
            "Speed: 3.0ms preprocess, 8.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 11.1ms\n",
            "Speed: 6.3ms preprocess, 11.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.3ms\n",
            "Speed: 5.0ms preprocess, 10.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.6ms\n",
            "Speed: 5.1ms preprocess, 10.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.8ms\n",
            "Speed: 4.9ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.9ms\n",
            "Speed: 4.1ms preprocess, 8.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 11.3ms\n",
            "Speed: 5.3ms preprocess, 11.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 12.7ms\n",
            "Speed: 4.1ms preprocess, 12.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 11.4ms\n",
            "Speed: 5.6ms preprocess, 11.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 13.3ms\n",
            "Speed: 3.4ms preprocess, 13.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 19.0ms\n",
            "Speed: 5.2ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.4ms\n",
            "Speed: 3.5ms preprocess, 8.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 13.0ms\n",
            "Speed: 5.8ms preprocess, 13.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.2ms\n",
            "Speed: 4.9ms preprocess, 8.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.8ms\n",
            "Speed: 3.9ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 14.1ms\n",
            "Speed: 3.4ms preprocess, 14.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.7ms\n",
            "Speed: 4.0ms preprocess, 8.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 15.4ms\n",
            "Speed: 4.5ms preprocess, 15.4ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 8.3ms\n",
            "Speed: 3.5ms preprocess, 8.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 1 twig, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 12.9ms\n",
            "Speed: 5.1ms preprocess, 12.9ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 16.2ms\n",
            "Speed: 7.2ms preprocess, 16.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 14.3ms\n",
            "Speed: 5.9ms preprocess, 14.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 18.1ms\n",
            "Speed: 5.4ms preprocess, 18.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 19.2ms\n",
            "Speed: 4.9ms preprocess, 19.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 19.9ms\n",
            "Speed: 6.2ms preprocess, 19.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1800\n",
            "\n",
            "0: 384x640 4 plastics, 13.7ms\n",
            "Speed: 4.8ms preprocess, 13.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 12.9ms\n",
            "Speed: 5.9ms preprocess, 12.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.7ms\n",
            "Speed: 2.8ms preprocess, 7.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 6.9ms\n",
            "Speed: 3.6ms preprocess, 6.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 13.4ms\n",
            "Speed: 6.6ms preprocess, 13.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.1ms\n",
            "Speed: 3.6ms preprocess, 7.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 plastics, 11.6ms\n",
            "Speed: 2.9ms preprocess, 11.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 6.8ms\n",
            "Speed: 3.6ms preprocess, 6.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.7ms\n",
            "Speed: 3.9ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.0ms\n",
            "Speed: 3.0ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.6ms\n",
            "Speed: 3.6ms preprocess, 7.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.8ms\n",
            "Speed: 5.7ms preprocess, 7.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.4ms\n",
            "Speed: 2.8ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 6.4ms\n",
            "Speed: 5.3ms preprocess, 6.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.7ms\n",
            "Speed: 4.7ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 8.4ms\n",
            "Speed: 3.0ms preprocess, 8.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.9ms\n",
            "Speed: 3.5ms preprocess, 8.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.1ms\n",
            "Speed: 4.3ms preprocess, 7.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 6.8ms\n",
            "Speed: 4.0ms preprocess, 6.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.3ms\n",
            "Speed: 4.3ms preprocess, 7.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.2ms\n",
            "Speed: 2.8ms preprocess, 9.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.1ms\n",
            "Speed: 4.1ms preprocess, 8.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 plastics, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.6ms\n",
            "Speed: 2.8ms preprocess, 8.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1850\n",
            "\n",
            "0: 384x640 4 plastics, 8.3ms\n",
            "Speed: 6.6ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.9ms\n",
            "Speed: 5.2ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.1ms\n",
            "Speed: 3.4ms preprocess, 7.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.3ms\n",
            "Speed: 5.2ms preprocess, 7.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 6.7ms\n",
            "Speed: 3.4ms preprocess, 6.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 7.8ms\n",
            "Speed: 4.1ms preprocess, 7.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 8.9ms\n",
            "Speed: 4.0ms preprocess, 8.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.9ms\n",
            "Speed: 4.8ms preprocess, 7.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 7.1ms\n",
            "Speed: 4.4ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 plastics, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 plastics, 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 4.1ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.9ms\n",
            "Speed: 4.2ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.6ms\n",
            "Speed: 4.3ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 6.9ms\n",
            "Speed: 3.7ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.2ms\n",
            "Speed: 5.6ms preprocess, 10.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.8ms\n",
            "Speed: 3.1ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.6ms\n",
            "Speed: 5.0ms preprocess, 9.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.1ms\n",
            "Speed: 6.7ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.3ms\n",
            "Speed: 4.3ms preprocess, 7.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 12.8ms\n",
            "Speed: 4.5ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.5ms\n",
            "Speed: 4.2ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1900\n",
            "\n",
            "0: 384x640 2 plastics, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.6ms\n",
            "Speed: 2.8ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.2ms\n",
            "Speed: 4.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.0ms\n",
            "Speed: 5.9ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 15.3ms\n",
            "Speed: 3.9ms preprocess, 15.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.2ms\n",
            "Speed: 4.7ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.6ms\n",
            "Speed: 3.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.9ms\n",
            "Speed: 3.2ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 plastics, 8.6ms\n",
            "Speed: 4.5ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 3.7ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.0ms\n",
            "Speed: 3.1ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 3.2ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.2ms\n",
            "Speed: 4.5ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 2.8ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 2.9ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.8ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 3.4ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 1950\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 3.3ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.5ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.3ms\n",
            "Speed: 3.7ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 2.9ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.9ms\n",
            "Speed: 5.0ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.5ms\n",
            "Speed: 4.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.4ms\n",
            "Speed: 2.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.0ms\n",
            "Speed: 4.5ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.4ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 6.7ms\n",
            "Speed: 3.7ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 18.5ms\n",
            "Speed: 6.9ms preprocess, 18.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 6.3ms\n",
            "Speed: 4.3ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 7.3ms\n",
            "Speed: 3.4ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 plastic, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.7ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 2.9ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.2ms\n",
            "Speed: 4.0ms preprocess, 7.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.1ms\n",
            "Speed: 4.8ms preprocess, 11.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.3ms\n",
            "Speed: 3.0ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.2ms\n",
            "Speed: 5.9ms preprocess, 13.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 2.6ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame: 2000\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 2.9ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 6.1ms\n",
            "Speed: 2.7ms preprocess, 6.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.4ms\n",
            "Speed: 3.7ms preprocess, 8.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.5ms\n",
            "Speed: 4.3ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 2.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.9ms\n",
            "Speed: 3.8ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ğŸ‰ ì˜ìƒ ì €ì¥ ì™„ë£Œ: /content/output_yolo.mp4\n"
          ]
        }
      ]
    }
  ]
}